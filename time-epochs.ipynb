{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "digital-anger",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "from pprint import pprint \n",
    "from importlib import reload\n",
    "import logging\n",
    "from typing import Callable\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "from tools import utilityTools as utility\n",
    "from tools import dataTools as dt\n",
    "import pyaldata as pyal\n",
    "\n",
    "%matplotlib inline\n",
    "reload(dt)\n",
    "\n",
    "root = pathlib.Path(\"/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-lloyd",
   "metadata": {},
   "source": [
    "# Compare different epochs\n",
    "\n",
    "the idea is to see whether canonical axes between 2 animals provide a higher VAF for time epochs in the trial that they have not been trained on, compared to, for example, M1-PMd axes in a single animal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-repair",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_id(trial):\n",
    "    return int(np.round((trial.target_direction + np.pi) / (0.25*np.pi))) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7c20a0-fb13-42ff-bef5-fd3eea0dab59",
   "metadata": {},
   "source": [
    "Based on the Gallego Nat Comm 2018 paper and some playing (data and projection matrices in the paper are row-wise): \n",
    "$$\\%VAF=\\frac{norm(X)-norm(X-XC^TA(A^TA)^{-1}A^TC)}{norm(X)}$$\n",
    "where:\n",
    "- $A$ is the CCA output, the output of the `canoncorr` function\n",
    "- $C$ is the `PCA_model.components_`\n",
    "- $X$ is the data matrix, $T\\times n$ with $T$ time points and $n$ neurons, and each neuron is **zero mean**\n",
    "- $norm$ is sum of squared elements  \n",
    "\n",
    "Seems to give reasonable results: lowering number of PCs reduces the VAF.\n",
    "\n",
    "However, there are problems:\n",
    "- the formulation in the paper, gives a VAF for each dimension, so the formula above should be applied to individual axes.\n",
    "- It is already implemented in MATLAB [here](https://github.com/limblab/proc-juan/blob/65dd81a1fc0ddb23def8039df9053a2be3e9bf88/paper_cross-task_manifold_review/vaf_CCs.m#L114), which uses the VAF function from the dPCA paper [here](https://github.com/machenslab/dPCA/blob/master/matlab/dpca_explainedVariance.m). I should translate that to compare?!?\n",
    "\n",
    "> The value above actually equals to the total VAF :)\n",
    "\n",
    "### dimension-wise VFA\n",
    "\n",
    "done!\n",
    "\n",
    "---\n",
    "\n",
    "back to the original idea:\n",
    "\n",
    "1. this:\n",
    "> # Compare different e\n",
    "pochs\n",
    "> the idea is to see whether canonical axes between 2 animals provide a higher VAF for time epochs in the trial that they have not been trained on, compared to, for example, M1-PMd axes in a single animal.\n",
    "\n",
    "2. and a similar but different idea:\n",
    "> two monkeys during the same epoch vs. one monkey between 2 different epochs.\n",
    "i.e., preparation vs execution, ...\n",
    "\n",
    "3. upper bound for VAF and for CCs:\n",
    "> within monkey and epoch and even target-matched, randomly select 2 subset of trials and the VAF/CCs will be the upper bound.\n",
    "\n",
    "#### Try the second idea first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "animalList = ['Chewie', 'Mihili']\n",
    "\n",
    "animalFiles={}\n",
    "for animal in animalList:\n",
    "    animalFiles[animal] = utility.find_file(root / animal,'mat')\n",
    "\n",
    "# just keeping the CS sessions\n",
    "goodFiles = [file for animal in animalFiles for file in animalFiles[animal] if 'CS' in file]\n",
    "\n",
    "# keeping 1 session per animal\n",
    "fileList = ['/data/Chewie/Chewie_CO_CS_2016-10-14.mat', '/data/Mihili/Mihili_CO_VR_2014-03-03.mat']\n",
    "# fileList = goodFiles\n",
    "\n",
    "\n",
    "df_data=[]\n",
    "for fname in fileList:\n",
    "    df = pyal.mat2dataframe(fname, shift_idx_fields=True)\n",
    "    df_data.append(df)\n",
    "    dt.summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-spanish",
   "metadata": {},
   "source": [
    "preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_exec_all_targets (df, n_components=10):\n",
    "    \"preprocessing for execution eopch\"\n",
    "    df[\"target_id\"] = df.apply(get_target_id, axis=1)  # add a field `target_id` with int values\n",
    "\n",
    "    df_= pyal.add_firing_rates(df, 'smooth')\n",
    "    \n",
    "    df_= pyal.select_trials(df_, df_.result== 'R')\n",
    "    df_= pyal.select_trials(df_, df_.epoch=='BL')\n",
    "    \n",
    "    if \"M1_spikes\" in df_.columns:\n",
    "        df_ = pyal.remove_low_firing_neurons(df_, \"M1_spikes\", 1)\n",
    "    if \"PMd_spikes\" in df_.columns:\n",
    "        df_ = pyal.remove_low_firing_neurons(df_, \"PMd_spikes\", 1)\n",
    "    \n",
    "    df_ = pyal.restrict_to_interval(df_, start_point_name='idx_movement_on', rel_start=0, rel_end=45)\n",
    "    \n",
    "    if \"M1_spikes\" in df_.columns:\n",
    "        M1_rates = np.concatenate(df_.M1_rates.values, axis=0)\n",
    "        pca_model = PCA(n_components=n_components, svd_solver='full');\n",
    "        pca_model.fit(M1_rates);\n",
    "        df_ = pyal.apply_dim_reduce_model(df_, pca_model, 'M1_rates', 'M1_pca');\n",
    "\n",
    "    if \"PMd_spikes\" in df_.columns:\n",
    "        PMd_rates = np.concatenate(df_.PMd_rates.values, axis=0)\n",
    "        pca_model = PCA(n_components=n_components, svd_solver='full');\n",
    "        pca_model.fit(PMd_rates);\n",
    "        df_ = pyal.apply_dim_reduce_model(df_, pca_model, 'PMd_rates', 'PMd_pca');\n",
    "\n",
    "    \n",
    "    return df_\n",
    "\n",
    "\n",
    "df_data_exec = [prep_exec_all_targets(df) for  df in df_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_prep_all_targets (df, n_components=10):\n",
    "    \"preprocessing for Preparation epoch\"\n",
    "    df[\"target_id\"] = df.apply(get_target_id, axis=1)  # add a field `target_id` with int values\n",
    "\n",
    "    df_= pyal.add_firing_rates(df, 'smooth')\n",
    "    \n",
    "    df_= pyal.select_trials(df_, df_.result== 'R')\n",
    "    df_= pyal.select_trials(df_, df_.epoch=='BL')\n",
    "    \n",
    "    if \"M1_spikes\" in df_.columns:\n",
    "        df_ = pyal.remove_low_firing_neurons(df_, \"M1_spikes\", 1)\n",
    "    if \"PMd_spikes\" in df_.columns:\n",
    "        df_ = pyal.remove_low_firing_neurons(df_, \"PMd_spikes\", 1)\n",
    "    \n",
    "    df_ = pyal.restrict_to_interval(df_, start_point_name='idx_movement_on', rel_start=-45, rel_end=0)\n",
    "    \n",
    "    if \"M1_spikes\" in df_.columns:\n",
    "        M1_rates = np.concatenate(df_.M1_rates.values, axis=0)\n",
    "        pca_model = PCA(n_components=n_components, svd_solver='full');\n",
    "        pca_model.fit(M1_rates);\n",
    "        df_ = pyal.apply_dim_reduce_model(df_, pca_model, 'M1_rates', 'M1_pca');\n",
    "\n",
    "    if \"PMd_spikes\" in df_.columns:\n",
    "        PMd_rates = np.concatenate(df_.PMd_rates.values, axis=0)\n",
    "        pca_model = PCA(n_components=n_components, svd_solver='full');\n",
    "        pca_model.fit(PMd_rates);\n",
    "        df_ = pyal.apply_dim_reduce_model(df_, pca_model, 'PMd_rates', 'PMd_pca');\n",
    "\n",
    "    \n",
    "    return df_\n",
    "\n",
    "\n",
    "df_data_prep = [prep_prep_all_targets(df) for  df in df_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-advance",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "CC=[]\n",
    "for target in range(8):\n",
    "    dfs_prep = [pyal.select_trials(df_,df_.target_id==target) for df_ in df_data_prep]\n",
    "    dfs_exec = [pyal.select_trials(df_,df_.target_id==target) for df_ in df_data_exec]\n",
    "    \n",
    "    # PMd prep: mon1~mon2\n",
    "    CC.append(dt.CCA_pyal(dfs_prep[0],'PMd_pca', dfs_prep[1],'PMd_pca'))\n",
    "    # M1 exec: mon1~mon2\n",
    "    CC.append(dt.CCA_pyal(dfs_exec[0],'M1_pca', dfs_exec[1],'M1_pca'))\n",
    "    # m1 mon1: prep~exec\n",
    "    CC.append(dt.CCA_pyal(dfs_prep[0],'M1_pca', dfs_exec[0],'M1_pca'))\n",
    "    # PMd mon1: prep~exec\n",
    "    CC.append(dt.CCA_pyal(dfs_prep[0],'PMd_pca', dfs_exec[0],'PMd_pca'))\n",
    "\n",
    "CC= np.array(CC)\n",
    "\n",
    "utility.shaded_errorbar(ax,CC[0::4,:].T, label='PMd prep: mon1~mon2')\n",
    "utility.shaded_errorbar(ax,CC[1::4,:].T, label='M1 exec: mon1~mon2')\n",
    "utility.shaded_errorbar(ax,CC[2::4,:].T,ls='--',label='m1 mon1: prep~exec')\n",
    "utility.shaded_errorbar(ax,CC[3::4,:].T,ls='--',label='PMd mon1: prep~exec')\n",
    "\n",
    "ax.set_xlabel('components')\n",
    "ax.set_ylabel('canonical correlation')\n",
    "ax.legend()\n",
    "ax.set_ylim([0,1])\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_title('CCA --- average across targets', usetex=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-clear",
   "metadata": {},
   "source": [
    "similar results from prep~exec of Monkey2:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "what about the VAF?  \n",
    "I'll look at VAF, instead of correlation, in the plot above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_general (df):\n",
    "    \"preprocessing general!\"\n",
    "    df[\"target_id\"] = df.apply(get_target_id, axis=1)  # add a field `target_id` with int values\n",
    "\n",
    "    df_= pyal.add_firing_rates(df, 'smooth')\n",
    "    \n",
    "    df_= pyal.select_trials(df_, df_.result== 'R')\n",
    "    df_= pyal.select_trials(df_, df_.epoch=='BL')\n",
    "    \n",
    "    df_ = pyal.remove_low_firing_neurons(df_, \"M1_spikes\", 3)\n",
    "    df_ = pyal.remove_low_firing_neurons(df_, \"PMd_spikes\", 3)\n",
    "    return df_\n",
    "\n",
    "\n",
    "df_data_ready = [prep_general(df) for  df in df_data]\n",
    "\n",
    "prep_epoch = pyal.generate_epoch_fun(start_point_name='idx_movement_on', rel_start=-45, rel_end=0)\n",
    "exec_epoch = pyal.generate_epoch_fun(start_point_name='idx_movement_on', rel_start=0, rel_end=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "\n",
    "CC=[]\n",
    "\n",
    "for target in range(8):\n",
    "    # PMd prep: mon1~mon2\n",
    "    a,b,_ = dt.VAF_pc_cc_pyal(df1=df_data_ready[1], field1='PMd_rates', epoch1=prep_epoch, target1=target,\n",
    "                            df2=df_data_ready[0], field2='PMd_rates', epoch2=prep_epoch, target2=target)\n",
    "    CC.append((a+b)/2)\n",
    "\n",
    "    # M1 exec: mon1~mon2\n",
    "    a,b,_ = dt.VAF_pc_cc_pyal(df1=df_data_ready[0], field1='M1_rates', epoch1=exec_epoch, target1=target,\n",
    "                            df2=df_data_ready[1], field2='M1_rates', epoch2=exec_epoch, target2=target)\n",
    "    CC.append((a+b)/2)\n",
    "\n",
    "    # m1 mon1: prep~exec\n",
    "    a,b,_ = dt.VAF_pc_cc_pyal(df1=df_data_ready[0], field1='M1_rates', epoch1=prep_epoch, target1=target,\n",
    "                            df2=df_data_ready[0], field2='M1_rates', epoch2=exec_epoch, target2=target)\n",
    "    CC.append((a+b)/2)\n",
    "\n",
    "    # PMd mon1: prep~exec\n",
    "    a,b,_ = dt.VAF_pc_cc_pyal(df1=df_data_ready[0], field1='PMd_rates', epoch1=prep_epoch, target1=target,\n",
    "                            df2=df_data_ready[0], field2='PMd_rates', epoch2=exec_epoch, target2=target)\n",
    "    CC.append((a+b)/2)\n",
    "\n",
    "\n",
    "CC= np.array(CC)\n",
    "\n",
    "utility.shaded_errorbar(ax,np.cumsum(CC[0::4,:].T,axis=0), label='PMd prep: mon1~mon2')\n",
    "utility.shaded_errorbar(ax,np.cumsum(CC[1::4,:].T,axis=0), label='M1 exec: mon1~mon2')\n",
    "utility.shaded_errorbar(ax,np.cumsum(CC[2::4,:].T,axis=0),ls='--',label='m1 mon1: prep~exec')\n",
    "utility.shaded_errorbar(ax,np.cumsum(CC[3::4,:].T,axis=0),ls='--',label='PMd mon1: prep~exec')\n",
    "\n",
    "ax.set_xlabel('components')\n",
    "ax.set_ylabel('cumulative VAF')\n",
    "ax.legend()\n",
    "ax.set_ylim([0,1])\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_title('VAF --- average across targets', usetex=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1f80b-7b9e-4691-8b01-d3a59f54d7db",
   "metadata": {},
   "source": [
    "CCa now  is applied to each target separately.  \n",
    "What if I keep the same number of trials to each target, sort them and then apply CCA to all of it only once?\n",
    "> I think it makes more sense, because realignment is due to neural turnover, not different targets.\n",
    "\n",
    "A few test cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134bd94-f54b-4789-8657-6b6105c9de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df_data_ready[1]\n",
    "field1='PMd_rates'\n",
    "epoch1=prep_epoch\n",
    "target1=3\n",
    "df2=df_data_ready[0]\n",
    "field2='PMd_rates'\n",
    "epoch2=prep_epoch\n",
    "target2=3\n",
    "\n",
    "\n",
    "df1 = pyal.restrict_to_interval(df1,epoch_fun=epoch1)\n",
    "rates_1 = np.concatenate(df1[field1].values, axis=0)\n",
    "rates_1 -= np.mean(rates_1,axis=0)\n",
    "rates_1_model = PCA(n_components=10, svd_solver='full').fit(rates_1)\n",
    "rates_1_C = rates_1_model.components_\n",
    "df1 = pyal.apply_dim_reduce_model(df1, rates_1_model, field1, '_pca');\n",
    "\n",
    "\n",
    "df1 = pyal.select_trials(df1, df1.target_id==target1)\n",
    "pca_1_target = np.concatenate(df1['_pca'].values, axis=0)\n",
    "\n",
    "\n",
    "df2 = pyal.restrict_to_interval(df2, epoch_fun=epoch2)\n",
    "rates_2 = np.concatenate(df2[field2].values, axis=0)\n",
    "rates_2 -= np.mean(rates_2,axis=0)\n",
    "rates_2_model = PCA(n_components=10, svd_solver='full').fit(rates_2)\n",
    "rates_2_C = rates_2_model.components_\n",
    "df2 = pyal.apply_dim_reduce_model(df2, rates_2_model, field2, '_pca');\n",
    "\n",
    "df2 = pyal.select_trials(df2, df2.target_id==target2)\n",
    "pca_2_target = np.concatenate(df2['_pca'].values, axis=0)\n",
    "\n",
    "\n",
    "# same number of timepoints in both matrices\n",
    "n_samples = min ([pca_1_target.shape[0], pca_2_target.shape[0]])\n",
    "pca_1_target = pca_1_target[:n_samples,:]\n",
    "pca_2_target = pca_2_target[:n_samples,:]\n",
    "\n",
    "A, B, _, _, _ = dt.canoncorr(pca_1_target, pca_2_target, fullReturn=True)\n",
    "VAFs1 = dt.VAF_pc_cc(rates_1, rates_1_C, A)\n",
    "VAFs2 = dt.VAF_pc_cc(rates_2, rates_2_C, B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138750d-68c0-4ad5-9141-336b91b7e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pyal.restrict_to_interval(df1,epoch_fun=epoch1)\n",
    "rates_1 = np.concatenate(df1[field1].values, axis=0)\n",
    "df2 = pyal.restrict_to_interval(df2, epoch_fun=epoch2)\n",
    "rates_2 = np.concatenate(df2[field2].values, axis=0)\n",
    "plt.plot(np.mean(rates_1,axis=0),'r')\n",
    "plt.plot(np.mean(rates_2,axis=0),'b')\n",
    "plt.xlabel('neuron #')\n",
    "plt.ylabel('average firing rate')\n",
    "plt.title('PMd prep: mon1~mon2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6078b-6a39-4449-9e30-65add0ae54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAFs1, sum(VAFs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74e0c0-2373-47cd-ae14-fb71fc7085ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, C, A= rates_1, rates_1_C, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb917095-8cb0-4c79-bd1a-a0dc8f7ef28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = lambda m:np.sum(m**2)\n",
    "\n",
    "D = linalg.inv(A.T@A)@A.T@C\n",
    "E = C.T@A\n",
    "\n",
    "X_ = X - X @ E[:,:5] @ D[:5,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884361c0-8097-41ec-a294-58afc8a64fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 1000\n",
    "plt.plot(X[offset:offset+1000, 10:20],'b');\n",
    "plt.plot(X_[offset:offset+1000,10:20],'--r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b3c541-cc61-4da3-ac90-cececc4bd277",
   "metadata": {},
   "source": [
    "Let's look at VAF within monkey and within area between targets, and to the same target and between subsets of trials just to check if we get an elbow:\n",
    "\n",
    "### VAF by canonical axes between targets\n",
    "\n",
    "just between pairs of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e97cde-814f-4701-8876-9780af01ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "CC1=[]\n",
    "R1 = []\n",
    "for tar1 in range(8):\n",
    "    for tar2 in range(tar1+1,8):\n",
    "\n",
    "        a,b,r = dt.VAF_pc_cc_pyal(df1=df_data_ready[0], field1='M1_rates', epoch1=exec_epoch, target1=tar1,\n",
    "                                df2=df_data_ready[0], field2='M1_rates', epoch2=exec_epoch, target2=tar2)\n",
    "        CC1.append((a+b)/2)\n",
    "        R1.append(r)\n",
    "\n",
    "        ax.plot(np.cumsum(CC1[-1]))\n",
    "\n",
    "ax.set_xlabel('components')\n",
    "ax.set_ylabel('cumulative VAF')\n",
    "ax.legend()\n",
    "ax.set_ylim([0,1])\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_title('M1 mon1 VAF --- across all pairs of targets', usetex=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4eac9-5366-4c3b-8565-f8342e3bb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "CC2=[]\n",
    "R2 = []\n",
    "for tar1 in range(8):\n",
    "    for tar2 in range(tar1+1,8):\n",
    "\n",
    "        a,b,r = dt.VAF_pc_cc_pyal(df1=df_data_ready[1], field1='M1_rates', epoch1=exec_epoch, target1=tar1,\n",
    "                                df2=df_data_ready[1], field2='M1_rates', epoch2=exec_epoch, target2=tar2)\n",
    "\n",
    "        CC2.append((a+b)/2)\n",
    "        R2.append(r)\n",
    "\n",
    "        ax.plot(np.cumsum(CC2[-1]))\n",
    "\n",
    "ax.set_xlabel('components')\n",
    "ax.set_ylabel('cumulative VAF')\n",
    "ax.legend()\n",
    "ax.set_ylim([0,1])\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_title('M1 mon2 VAF --- across all pairs of targets', usetex=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a8c5b-883e-4bb2-bf63-dd109e946a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCs1= np.array(CC1).T\n",
    "Rs1= np.array(R1).T\n",
    "\n",
    "CCs2= np.array(CC2).T\n",
    "Rs2= np.array(R2).T\n",
    "\n",
    "\n",
    "plt.plot(Rs1);\n",
    "plt.figure()\n",
    "plt.plot(Rs2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78913208-6940-4eb2-b89e-cba6f98570f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_ready[1].M1_rates[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426167c3-84e2-4923-807e-e31ad89b81bd",
   "metadata": {},
   "source": [
    "### VAF by canonical axes between subsets of trials to the same targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb6308-1a68-4729-b20c-2e6c047fd382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "644f6ce68e21c63884a7612d4a868a789d171f940bc4242f53afa3c8321510f0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
