{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd276e87",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5473a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "from pprint import pprint\n",
    "import gc\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "from tools import utilityTools as utility\n",
    "from tools import dataTools as dt\n",
    "import pyaldata as pyal\n",
    "\n",
    "%matplotlib inline\n",
    "reload(dt)\n",
    "\n",
    "# Global params\n",
    "root = pathlib.Path(\"/data\")\n",
    "lower_bound_pickle = '/data/lower-bound-datasets.p'\n",
    "\n",
    "BIN_SIZE = .03  # sec\n",
    "WINDOW_prep = (-.39, .06)  # sec\n",
    "WINDOW_exec = (-.12, .42)  # sec\n",
    "n_components = 10  # min between M1 and PMd\n",
    "areas = ('M1', 'PMd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ee939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_id(trial):\n",
    "    return int(np.round((trial.target_direction + np.pi) / (0.25*np.pi))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbe3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataset_selection.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162ef8e",
   "metadata": {},
   "source": [
    "## Control\n",
    "\n",
    "let's find a lower-bound. Canonical correlation without matching the animal, the area, the epoch and the target!\n",
    "\n",
    "### Details\n",
    "- **animal**: $C_L$  is Chewie\n",
    "- **window**: For *M1* it is $-120ms \\sim +420ms$ and for *PMd* from $-390ms  \\sim +60ms$\n",
    "- **dim**: it is 10 for M1 and 15 for PMd\n",
    "- **preprocessing**: \n",
    "    - remove firing rate below 1Hz overall\n",
    "    - bin to 30ms\n",
    "    - square root transform\n",
    "    - smooth by Gaussian kernel, $\\sigma=50ms$\n",
    "    \n",
    "\n",
    "\n",
    "**do not run the next 2 cells, if there is a pickle file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairFileList = []\n",
    "for animal1 in GoodDataList[areas[0]]:\n",
    "    for animal2 in GoodDataList[areas[1]]:\n",
    "        if animal2  == animal1 or '2' in animal1 or '2' in animal2:  # to remove Chewie2\n",
    "            continue\n",
    "        path1List = [root/animal1/GoodDataList[areas[0]][animal1][i] for i,_ in enumerate(GoodDataList[areas[0]][animal1])]\n",
    "        path2List = [root/animal2/GoodDataList[areas[1]][animal2][i] for i,_ in enumerate(GoodDataList[areas[1]][animal2])]\n",
    "        for path1 in path1List:\n",
    "            for path2 in path2List:\n",
    "                pairFileList.append((pyal.mat2dataframe(path1, shift_idx_fields=True),\n",
    "                                     pyal.mat2dataframe(path2, shift_idx_fields=True)\n",
    "                                    )\n",
    "                                   )\n",
    "        \n",
    "print(f'{len(pairFileList)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5fcfc-a747-4cc9-9768-1d35cf49a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_general (df, area='M1'):\n",
    "    \"preprocessing general!\"\n",
    "    \n",
    "    df[\"target_id\"] = df.apply(get_target_id, axis=1)  # add a field `target_id` with int values\n",
    "\n",
    "    df_ = pyal.remove_low_firing_neurons(df, f\"{area}_spikes\", 1)\n",
    "    \n",
    "    df_= pyal.select_trials(df, df.result== 'R')\n",
    "    df_= pyal.select_trials(df_, df_.epoch=='BL')\n",
    "    \n",
    "    assert np.all(df_.bin_size == .01), 'bin size is not consistent!'\n",
    "    df_ = pyal.combine_time_bins(df_, int(BIN_SIZE/.01))\n",
    "    \n",
    "    df_ = pyal.sqrt_transform_signal(df_, f\"{area}_spikes\")\n",
    "        \n",
    "    df_= pyal.add_firing_rates(df_, 'smooth', std=0.05)\n",
    "    \n",
    "    \n",
    "    return df_\n",
    "\n",
    "gc.collect()\n",
    "pairFileList_ready = [(prep_general(df1),prep_general(df2)) for  df1,df2 in pairFileList]\n",
    "del pairFileList\n",
    "gc.collect()\n",
    "with open(root/lower_bound_pickle,'wb') as f:\n",
    "    pickle.dump(pairFileList_ready, f)\n",
    "# to save memory\n",
    "del pairFileList_ready, f\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8becf82-4d75-449c-a93a-30e3b729b008",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*load the pickle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c951a-2447-4b69-840d-18cc8c036860",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root/lower_bound_pickle,'rb') as f:\n",
    "    pairFileList_ready = pickle.load(f)\n",
    "\n",
    "prep_epoch = pyal.generate_epoch_fun(start_point_name='idx_movement_on',\n",
    "                                     rel_start=int(WINDOW_prep[0]/BIN_SIZE),\n",
    "                                     rel_end=int(WINDOW_prep[1]/BIN_SIZE)\n",
    "                                    )\n",
    "exec_epoch = pyal.generate_epoch_fun(start_point_name='idx_movement_on', \n",
    "                                     rel_start=int(WINDOW_exec[0]/BIN_SIZE),\n",
    "                                     rel_end=int(WINDOW_exec[1]/BIN_SIZE)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad62aca3",
   "metadata": {},
   "source": [
    "collecting all the data in a matrix, `AllData`: $sessions \\times targets \\times  trials \\times time \\times PCs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "side1df = [df for df,_ in pairFileList_ready]\n",
    "side2df = [df for _,df in pairFileList_ready]\n",
    "\n",
    "AllData1 = dt.get_data_array(side1df, prep_epoch, area='M1', n_components=n_components)\n",
    "AllData2 = dt.get_data_array(side2df, exec_epoch, area='PMd', n_components=n_components)\n",
    "\n",
    "_,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5c11d",
   "metadata": {},
   "source": [
    "do the CCA calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCs=[]\n",
    "for session, (sessionData1,sessionData2) in enumerate(zip(AllData1,AllData2)):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,n_components))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,-min_time:,:], (-1,n_components))\n",
    "    CCs.append(np.mean(dt.canoncorr(data1, data2)[:4]))\n",
    "CCs = np.array(CCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CCs.T,'.')\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b2407",
   "metadata": {},
   "source": [
    "the average distribution of CCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCs=[]\n",
    "for session, (sessionData1,sessionData2) in enumerate(zip(AllData1,AllData2)):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,n_components))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,n_components))\n",
    "    CCs.append(dt.canoncorr(data1, data2))\n",
    "CCs = np.array(CCs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(CCs,axis=1), '--o')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72da6499f934495e06c03d484049d4696c0f7b78c6b9c64cf8676e9ec2014a6a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
