{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06debf48",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f206a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os, sys, pathlib\n",
    "from pprint import pprint\n",
    "import gc\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging, warnings\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyaldata as pyal\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "    try:\n",
    "        nbPath = pathlib.Path.cwd()\n",
    "        RepoPath = nbPath.parent\n",
    "        os.chdir(RepoPath)\n",
    "\n",
    "        from tools import utilityTools as utility\n",
    "        from tools import dataTools as dt\n",
    "        from tools import lstm\n",
    "        import params\n",
    "        mouse_defs = params.mouse_defs\n",
    "        defs = mouse_defs\n",
    "\n",
    "        set_rc =  params.set_rc_params\n",
    "        set_rc()\n",
    "        root = params.root\n",
    "        reload(dt)\n",
    "        reload(defs)\n",
    "        reload(params)\n",
    "    finally:\n",
    "        os.chdir(nbPath)\n",
    "    \n",
    "    \n",
    "    %run \"S1-mouse-M1-decoding.ipynb\"\n",
    "    \n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e751f1c-f06c-4fe4-a0bc-b2389ed43729",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1\n",
    "\n",
    "functions that plot each panel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6334d0-a764-4eb0-95e9-8839b9141f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def get_full_mouse_data():\n",
    "    defs = mouse_defs\n",
    "    \n",
    "    animalList = ['mouse-data']\n",
    "    animalFiles = []\n",
    "    for animal in animalList:\n",
    "        animalFiles.extend(utility.find_file(root / animal, 'mat'))\n",
    "\n",
    "    AllDFs=[]\n",
    "    for fname in animalFiles:\n",
    "        df = dt.load_pyal_data(fname)\n",
    "        df['mouse'] = fname.split(os.sep)[-1][fname.split(os.sep)[-1].find('WR'):].split('_')[0]\n",
    "        df['file'] = fname.split(os.sep)[-1]\n",
    "        df = defs.prep_general_mouse(df)\n",
    "        AllDFs.append(df)\n",
    "\n",
    "    allDFs_M1 = []\n",
    "    for df in AllDFs:\n",
    "        if 'M1_rates' in df.columns:\n",
    "            allDFs_M1.append(df)\n",
    "\n",
    "\n",
    "    allDFs_Str = []\n",
    "    for df in AllDFs:\n",
    "        if 'Str_rates' in df.columns:\n",
    "            allDFs_Str.append(df)\n",
    "            \n",
    "    return allDFs_M1, allDFs_Str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b1374-2c25-4583-ac98-64cb40ed431c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c0408e-e62e-43ac-8bec-4d908c4ca903",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_m1_decoding(ax, AllDFs):\n",
    "    defs = mouse_defs\n",
    "    \n",
    "    reg_scores = []\n",
    "    for i, df in enumerate(AllDFs):\n",
    "        AllData, AllVel = defs.get_data_array_and_vel([df], defs.exec_epoch_decode, area=defs.areas[0],\n",
    "                                                      n_components=defs.n_components)\n",
    "        # adding history\n",
    "        AllData = dt.add_history_to_data_array(AllData, defs.MAX_HISTORY)\n",
    "        AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "        AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "\n",
    "        *_,n_time,n_comp = AllData.shape\n",
    "        AllData1 = AllData[0,...]\n",
    "        AllVel1 = AllVel[0,...]\n",
    "\n",
    "        # resizing\n",
    "        X1 = AllData1.reshape((-1, n_time, n_comp))\n",
    "        AllVel1 = AllVel1.reshape((-1,n_time,3))\n",
    "\n",
    "        kf = KFold(n_splits=10)\n",
    "        for train_index, test_index in kf.split(X1[:,0,0]):\n",
    "            \n",
    "            x_train, x_test = X1[train_index,...], X1[test_index,...]\n",
    "            y_train, y_test = AllVel1[train_index,...], AllVel1[test_index,...]\n",
    "\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=X1.shape[-1], output_dims=3)\n",
    "            lstm_model.fit(x_train=x_train, y_train=y_train)\n",
    "            lstm_model.predict(x_test, y_test)\n",
    "            reg_scores.append(lstm_model.score.mean())\n",
    "\n",
    "    pop_score_day = np.array(reg_scores)\n",
    "\n",
    "\n",
    "    #=========================\n",
    "    pairIndex_across = []\n",
    "    for i, df1 in enumerate(AllDFs):\n",
    "        animal1 = df1.mouse[0]\n",
    "        pairIndex_across.append((i,[]))\n",
    "        for j, df2 in enumerate(AllDFs):\n",
    "            if j<i: continue\n",
    "            animal2 = df2.mouse[0]\n",
    "            if animal1 == animal2: continue\n",
    "            pairIndex_across[-1][1].append(j)\n",
    "    pairIndex_across = [(i,j) for i,jList in pairIndex_across for j in jList]\n",
    "    \n",
    "    reg_scores_across = []\n",
    "    for _, (id1, testId) in enumerate(pairIndex_across):\n",
    "        AllData, AllVel = defs.get_data_array_and_vel([AllDFs[id1],AllDFs[testId]], defs.exec_epoch_decode,\n",
    "                                                      area=defs.areas[0], n_components=defs.n_components)\n",
    "\n",
    "        # adding history\n",
    "        AllData = dt.add_history_to_data_array(AllData, defs.MAX_HISTORY)\n",
    "        AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "        AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "\n",
    "\n",
    "        AllData1 = AllData[0,...]\n",
    "        AllData2 = AllData[1,...]\n",
    "        AllVel1 = AllVel[0,...]\n",
    "        AllVel2 = AllVel[1,...]\n",
    "        \n",
    "        # resizing\n",
    "        _,n_trial,n_time,n_comp = np.min(np.array((AllData1.shape,AllData2.shape)),axis=0)\n",
    "        X1 = AllData1.reshape((-1,n_comp))\n",
    "        X2 = AllData2.reshape((-1,n_comp))\n",
    "        AllVel1 = AllVel1.reshape((-1,n_time,3))\n",
    "        AllVel2 = AllVel2.reshape((-1,n_time,3))\n",
    "\n",
    "        *_,U,V = dt.canoncorr(X1, X2, fullReturn=True)\n",
    "        U = U.reshape((-1,n_time,n_comp))\n",
    "        V = V.reshape((-1,n_time,n_comp))\n",
    "\n",
    "        lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=3)\n",
    "        lstm_model.fit(x_train=U, y_train=AllVel1)\n",
    "        lstm_model.predict(V, AllVel2)\n",
    "        reg_scores_across.append(lstm_model.score.mean())\n",
    "\n",
    "    pop_score_across = np.array(reg_scores_across)\n",
    "\n",
    "    #================================\n",
    "    reg_latent_scores = []\n",
    "    for id1, testId in pairIndex_across:\n",
    "        AllData, AllVel = defs.get_data_array_and_vel([AllDFs[id1],AllDFs[testId]], defs.exec_epoch_decode,\n",
    "                                                      area=defs.areas[0], n_components=defs.n_components)\n",
    "\n",
    "        # adding history\n",
    "        AllData = dt.add_history_to_data_array(AllData, defs.MAX_HISTORY)\n",
    "        AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "        AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "\n",
    "        AllData1 = AllData[0,...]\n",
    "        AllData2 = AllData[1,...]\n",
    "        AllVel1 = AllVel[0,...]\n",
    "        AllVel2 = AllVel[1,...]\n",
    "        # resizing\n",
    "        _,n_trial,n_time,n_comp = np.min(np.array((AllData1.shape, AllData2.shape)),axis=0)\n",
    "        X1 = AllData1.reshape((-1,n_time,n_comp))\n",
    "        X2 = AllData2.reshape((-1,n_time,n_comp))\n",
    "        AllVel2 = AllVel2.reshape((-1,n_time,3))\n",
    "        AllVel1 = AllVel1.reshape((-1,n_time,3))\n",
    "        crs_val_factor = int(0.9 * X1.shape[0])\n",
    "\n",
    "        # train the decoder\n",
    "        U,V = X1, X2\n",
    "        lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=3)\n",
    "        lstm_model.fit(x_train=U[:crs_val_factor,...], y_train=AllVel1[:crs_val_factor,...])\n",
    "        lstm_model.predict(V[:crs_val_factor,...], AllVel2[:crs_val_factor,...])\n",
    "        reg_scores_across.append(lstm_model.score.mean())\n",
    "    pop_latent_score = np.array(reg_scores_across)\n",
    "\n",
    "#======================== PLOTTING\n",
    "\n",
    "    bins = np.arange(0,1,0.05)\n",
    "    ax.hist(pop_score_across, bins=bins, density=True, label='Across\\n' r'(\\textit{aligned})',\n",
    "            alpha=.8, color=params.colors.MainCC)\n",
    "    ax.hist(pop_latent_score, bins=bins, density=True, label='Across\\n' r'(\\textit{unaligned})',\n",
    "            alpha=.8, color=params.colors.LowerCC)\n",
    "    ax.hist(pop_score_day, bins=bins, density=True, label='Within',\n",
    "            alpha=.8, color=params.colors.UpperCC)\n",
    "\n",
    "    ax.set_xlabel('Prediction accuracy ($R^2$)')\n",
    "    ax.set_ylabel('Probability density', labelpad=1)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([-.05,1])\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_bounds([0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a7318-01fb-417d-8292-6b861e9d4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "    fig=plt.figure(dpi=100)\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    \n",
    "    # allDFs_M1, _ = get_full_mouse_data()\n",
    "    \n",
    "    plot_m1_decoding(ax, allDFs_M1)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57de5a-38b2-422b-a50d-184660959178",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Plot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de05a700-b989-4d61-bc3f-7a627c8f7222",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed: `get_full_mouse_data` in 1.2s\n",
      "Running: `plot_m1_decoding`...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:05<00:00,  1.79it/s]"
     ]
    }
   ],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "    figsize= params.panels.decoding_hist\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    \n",
    "   \n",
    "    \n",
    "    ##########################################\n",
    "    # 1: Decoding for mouse M1\n",
    "    gs1   =utility.add_gridspec_abs(fig, nrows=1, ncols=1,\n",
    "                                    top=figsize[0],\n",
    "                                    right=figsize[1],\n",
    "                                    width=params.panels.decoding_hist[0],\n",
    "                                    height=params.panels.decoding_hist[1])\n",
    "\n",
    "    ax1 = fig.add_subplot(gs1[0])\n",
    "\n",
    "       \n",
    "    allDFs_M1, _ = get_full_mouse_data()\n",
    "    \n",
    "    plot_m1_decoding(ax1, allDFs_M1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#     AXES=(ax1,ax2,ax3,ax4,ax5,ax6)\n",
    "#     OFFX=np.array([.02]*len(AXES))\n",
    "#     OFFY=np.array([.03]*len(AXES))\n",
    "#     # OFFX[[-1]]=0.12\n",
    "#     # OFFX[[1]]=0.06\n",
    "    \n",
    "#     params.add_panel_caption(axes=AXES, offsetX=OFFX, offsetY=OFFY)\n",
    "\n",
    "    fig.savefig(params.figPath / 'figureS1-mouse-M1-decoding.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fd4b1-d6ba-4e85-9d10-40a5e3161a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "146bff742f048d001dec7fafb91c8daeb769f9aeaad9c8d129a83c9f9fb9a9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cca')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
