{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06debf48",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os, sys, pathlib\n",
    "from pprint import pprint\n",
    "import gc\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging, warnings\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyaldata as pyal\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "    try:\n",
    "        nbPath = pathlib.Path.cwd()\n",
    "        RepoPath = nbPath.parent\n",
    "        os.chdir(RepoPath)\n",
    "\n",
    "        from tools import utilityTools as utility\n",
    "        from tools import dataTools as dt\n",
    "        from tools import lstm\n",
    "        import params\n",
    "        mouse_defs = params.mouse_defs\n",
    "        defs = mouse_defs\n",
    "\n",
    "        set_rc =  params.set_rc_params\n",
    "        set_rc()\n",
    "        root = params.root\n",
    "        reload(dt)\n",
    "        reload(defs)\n",
    "        reload(params)\n",
    "    finally:\n",
    "        os.chdir(nbPath)\n",
    "    \n",
    "    \n",
    "    %run \"S1-mouse-M1-decoding.ipynb\"\n",
    "    \n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e751f1c-f06c-4fe4-a0bc-b2389ed43729",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1\n",
    "\n",
    "functions that plot each panel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6334d0-a764-4eb0-95e9-8839b9141f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def get_full_mouse_data():\n",
    "    defs = mouse_defs\n",
    "    \n",
    "    animalList = ['mouse-data']\n",
    "    animalFiles = []\n",
    "    for animal in animalList:\n",
    "        animalFiles.extend(utility.find_file(root / animal, 'mat'))\n",
    "\n",
    "    AllDFs=[]\n",
    "    for fname in animalFiles:\n",
    "        df = dt.load_pyal_data(fname)\n",
    "        df['mouse'] = fname.split(os.sep)[-1][fname.split(os.sep)[-1].find('WR'):].split('_')[0]\n",
    "        df['file'] = fname.split(os.sep)[-1]\n",
    "        df = defs.prep_general_mouse(df)\n",
    "        AllDFs.append(df)\n",
    "\n",
    "    allDFs_M1 = []\n",
    "    for df in AllDFs:\n",
    "        if 'M1_rates' in df.columns:\n",
    "            allDFs_M1.append(df)\n",
    "\n",
    "\n",
    "    allDFs_Str = []\n",
    "    for df in AllDFs:\n",
    "        if 'Str_rates' in df.columns:\n",
    "            allDFs_Str.append(df)\n",
    "            \n",
    "    return allDFs_M1, allDFs_Str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b1374-2c25-4583-ac98-64cb40ed431c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0408e-e62e-43ac-8bec-4d908c4ca903",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_m1_decoding(ax, AllDFs):\n",
    "    defs = mouse_defs\n",
    "    \n",
    "    #=========================\n",
    "    within_score = {}\n",
    "    aligned_score = {}\n",
    "    unaligned_score = {}\n",
    "    for i, df1 in enumerate(tqdm(AllDFs)):\n",
    "        animal1 = df1.mouse[0]\n",
    "\n",
    "        AllData, AllVel = defs.get_data_array_and_vel([df1], defs.exec_epoch_decode, area=defs.areas[0],\n",
    "                                                    n_components=defs.n_components)\n",
    "        # adding history\n",
    "        AllData = dt.add_history_to_data_array(AllData, defs.MAX_HISTORY)\n",
    "        AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "        AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "        *_,n_time,n_comp = AllData.shape\n",
    "        AllData1 = AllData[0,...]\n",
    "        AllVel1 = AllVel[0,...]\n",
    "        # resizing\n",
    "        X1 = AllData1.reshape((-1, n_time, n_comp))\n",
    "        AllVel1 = AllVel1.reshape((-1,n_time,3))\n",
    "\n",
    "        fold_score =[]\n",
    "        kf = KFold(n_splits=10)\n",
    "        for train_index, test_index in kf.split(X1[:,0,0]):\n",
    "            x_train, x_test = X1[train_index,...], X1[test_index,...]\n",
    "            y_train, y_test = AllVel1[train_index,...], AllVel1[test_index,...]\n",
    "\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=X1.shape[-1], output_dims=3)\n",
    "            lstm_model.fit(x_train=x_train, y_train=y_train, epochs = 10)\n",
    "            lstm_model.predict(x_test, y_test)\n",
    "            fold_score.append(lstm_model.score)\n",
    "        fold_score = np.median(fold_score)\n",
    "        within_score[df1.file[0]] = fold_score\n",
    "\n",
    "\n",
    "        aligned_score[df1.file[0]] = {}\n",
    "        unaligned_score[df1.file[0]] = {}\n",
    "        for j, df2 in enumerate(AllDFs):\n",
    "            if j < i: continue\n",
    "            animal2 = df2.mouse[0]\n",
    "            if animal1 == animal2: continue\n",
    "            \n",
    "            #================================\n",
    "            # Across sesisons\n",
    "            AllData, AllVel = defs.get_data_array_and_vel([df1, df2], defs.exec_epoch_decode,\n",
    "                                                          area=defs.areas[0], n_components=defs.n_components)\n",
    "\n",
    "            # adding history\n",
    "            AllData = dt.add_history_to_data_array(AllData, defs.MAX_HISTORY)\n",
    "            AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "            AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "            AllData1 = AllData[0,...]\n",
    "            AllData2 = AllData[1,...]\n",
    "            AllVel1 = AllVel[0,...]\n",
    "            AllVel2 = AllVel[1,...]\n",
    "            # resizing\n",
    "            _,n_trial,n_time,n_comp = AllData1.shape\n",
    "            X1 = AllData1.reshape((-1,n_comp))\n",
    "            X2 = AllData2.reshape((-1,n_comp))\n",
    "            AllVel1 = AllVel1.reshape((-1,n_time,3))\n",
    "            AllVel2 = AllVel2.reshape((-1,n_time,3))\n",
    "            \n",
    "            #================================\n",
    "            # Aligned\n",
    "            *_,U,V = dt.canoncorr(X1, X2, fullReturn=True)\n",
    "            U = U.reshape((-1,n_time,n_comp))\n",
    "            V = V.reshape((-1,n_time,n_comp))\n",
    "            X1 = X1.reshape((-1,n_time,n_comp))\n",
    "            X2 = X2.reshape((-1,n_time,n_comp))\n",
    "\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=3)\n",
    "            lstm_model.fit(x_train=U, y_train=AllVel1)\n",
    "            lstm_model.predict(V, AllVel2)\n",
    "            aligned_score[df1.file[0]][df2.file[0]] = lstm_model.score.mean()\n",
    "\n",
    "            #================================\n",
    "            # Unaligned\n",
    "            lstm_model1 = lstm.LSTMDecoder(input_dims=X1.shape[-1], output_dims=3)\n",
    "            lstm_model1.fit(x_train=X1, y_train=AllVel1)\n",
    "            lstm_model1.predict(X2, AllVel2)\n",
    "            lstm_model2 = lstm.LSTMDecoder(input_dims=X1.shape[-1], output_dims=3)\n",
    "            lstm_model2.fit(x_train=X2, y_train=AllVel2)\n",
    "            lstm_model2.predict(X1, AllVel1)\n",
    "\n",
    "            unaligned_score[df1.file[0]][df2.file[0]] = (lstm_model1.score.mean() + lstm_model2.score.mean()) / 2\n",
    "\n",
    "\n",
    "    # return within_score, aligned_score, unaligned_score\n",
    "    #======================== PLOTTING\n",
    "    pop_within = np.array(list(within_score.values()))\n",
    "    pop_aligned = np.array([val for key in aligned_score for val in aligned_score[key].values()])\n",
    "    pop_unaligned = np.array([val for key in unaligned_score for val in unaligned_score[key].values()])\n",
    "\n",
    "    ax.errorbar(1, pop_aligned.mean(), np.std(pop_aligned), label='Across\\n' r'(\\textit{aligned})',\n",
    "                color=params.colors.MainCC, fmt='-o', capsize=1.5)    \n",
    "    ax.errorbar(0, pop_unaligned.mean(), np.std(pop_unaligned), label='Across\\n' r'(\\textit{unaligned})',\n",
    "                color=params.colors.LowerCC, fmt='-o', capsize=1.5)\n",
    "    ax.errorbar(2, pop_within.mean(), np.std(pop_within), label='Within',\n",
    "                color=params.colors.UpperCC, fmt='-o', capsize=1.5)\n",
    "\n",
    "    unal_vals = []\n",
    "    al_vals = []\n",
    "    wi_vals = []\n",
    "    for file1, nested_dict in aligned_score.items():\n",
    "        wi_val1 = within_score[file1]\n",
    "        for file2, al_val in nested_dict.items():\n",
    "            wi_val2 = within_score[file2]\n",
    "            unal_val = unaligned_score[file1][file2]\n",
    "            ax.plot([0,1,2], [unal_val, al_val, wi_val1],\n",
    "                    color='gray', lw=.2, zorder=6, marker = 'o', ms=.1, alpha=.2)\n",
    "            ax.plot([1,2], [al_val, wi_val2],\n",
    "                    color='gray', lw=.2, zorder=6, marker = 'o', ms=.1, alpha=.2)\n",
    "            #for stats\n",
    "            unal_vals.append(unal_val)\n",
    "            al_vals.append(al_val)\n",
    "            wi_vals.append(wi_val1)\n",
    "            wi_vals.append(wi_val2)\n",
    "\n",
    "    ax.set_xlim([-0.2,2.2])\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(['Across\\n' r'(\\textit{unaligned})',\n",
    "                        'Across\\n' r'(\\textit{aligned})',\n",
    "                        'Within'])\n",
    "    ax.set_ylabel('Prediction accuracy ($R^2$)')\n",
    "    ax.set_ylim([-.05,.85])\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_bounds([0,2])\n",
    "    ax.spines['left'].set_bounds([0,.8])\n",
    "\n",
    "    #stats ###########################################################################\n",
    "    #calc stats\n",
    "    ##for paired stats\n",
    "    compare_upper_stats = stats.wilcoxon(np.repeat(al_vals,2), wi_vals)\n",
    "    compare_lower_stats = stats.wilcoxon(al_vals, unal_vals)\n",
    "\n",
    "    print(\"Across vs within:\", compare_upper_stats)\n",
    "    print(\"Across vs control:\", compare_lower_stats)\n",
    "\n",
    "    #annotate stats\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    liney = ymax*0.95\n",
    "    texty = ymax*1\n",
    "    line_kwargs = dict(linewidth = 0.5, color = 'k')\n",
    "    text_kwargs = dict(ha='center', va='center')\n",
    "\n",
    "    ax.plot([0,1], [liney, liney], **line_kwargs)\n",
    "    ax.plot([1,2], [liney, liney], linestyle = '--', **line_kwargs)\n",
    "    \n",
    "    ax.text(0.5, texty, dt.get_signif_annot(compare_upper_stats[1]), **text_kwargs)\n",
    "    ax.text(1.5, texty, dt.get_signif_annot(compare_lower_stats[1]), **text_kwargs)\n",
    "\n",
    "\n",
    "    return within_score, aligned_score, unaligned_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a7318-01fb-417d-8292-6b861e9d4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "    fig=plt.figure(dpi=100)\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    \n",
    "    allDFs_M1, _ = get_full_mouse_data()\n",
    "    \n",
    "    wi_val, al_val, un_val = plot_m1_decoding(ax, allDFs_M1)\n",
    "    # plt.savefig(('dummy.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57de5a-38b2-422b-a50d-184660959178",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Plot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05a700-b989-4d61-bc3f-7a627c8f7222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "    figsize= params.panels.decoding_hist\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    \n",
    "   \n",
    "    \n",
    "    ##########################################\n",
    "    # 1: Decoding for mouse M1\n",
    "    gs1   =utility.add_gridspec_abs(fig, nrows=1, ncols=1,\n",
    "                                    top=figsize[0],\n",
    "                                    right=figsize[1],\n",
    "                                    width=params.panels.decoding_hist[0],\n",
    "                                    height=params.panels.decoding_hist[1])\n",
    "\n",
    "    ax1 = fig.add_subplot(gs1[0])\n",
    "\n",
    "       \n",
    "    allDFs_M1, _ = get_full_mouse_data()\n",
    "    \n",
    "    plot_m1_decoding(ax1, allDFs_M1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#     AXES=(ax1,ax2,ax3,ax4,ax5,ax6)\n",
    "#     OFFX=np.array([.02]*len(AXES))\n",
    "#     OFFY=np.array([.03]*len(AXES))\n",
    "#     # OFFX[[-1]]=0.12\n",
    "#     # OFFX[[1]]=0.06\n",
    "    \n",
    "#     params.add_panel_caption(axes=AXES, offsetX=OFFX, offsetY=OFFY)\n",
    "\n",
    "    fig.savefig(params.figPath / 'figureS1-mouse-M1-decoding.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f2f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f438ab41c639bccf4a0690d593feedbc6f327eadb4a78567565a57c35fedcdae"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('cca': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "146bff742f048d001dec7fafb91c8daeb769f9aeaad9c8d129a83c9f9fb9a9b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
