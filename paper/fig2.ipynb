{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b102c0",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00059128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:20:41.640701Z",
     "iopub.status.busy": "2022-09-06T16:20:41.640396Z",
     "iopub.status.idle": "2022-09-06T16:20:42.766382Z",
     "shell.execute_reply": "2022-09-06T16:20:42.765945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os, pathlib\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging, warnings\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import PyPDF2 as ppdf\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import wilcoxon, linregress\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter\n",
    "\n",
    "import pyaldata as pyal\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "    try:\n",
    "        NBPath = pathlib.Path.cwd()\n",
    "        RepoPath = NBPath.parent\n",
    "        os.chdir(RepoPath)\n",
    "\n",
    "        from tools import utilityTools as utility\n",
    "        from tools import dataTools as dt\n",
    "        from tools import lstm\n",
    "        import params\n",
    "        monkey_defs = params.monkey_defs\n",
    "        mouse_defs = params.mouse_defs\n",
    "\n",
    "        set_rc =  params.set_rc_params\n",
    "        set_rc()\n",
    "        root = params.root\n",
    "\n",
    "        os.chdir(RepoPath / 'monkey')\n",
    "        %run \"_dataset-selection.ipynb\"\n",
    "\n",
    "    finally:\n",
    "        os.chdir(NBPath)\n",
    "\n",
    "    # %run \"fig2.ipynb\"\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "FIGPATH = params.figPath / 'fig2'\n",
    "if not os.path.exists(FIGPATH):\n",
    "    os.makedirs(FIGPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa2e5d-f25c-405a-ba73-2b2464c37b9e",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "functions that plot each panel.\n",
    "\n",
    "---\n",
    "\n",
    "Raster panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a84f30-d28c-42f1-ab20-79d6fd981655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:20:42.768219Z",
     "iopub.status.busy": "2022-09-06T16:20:42.768100Z",
     "iopub.status.idle": "2022-09-06T16:20:42.773367Z",
     "shell.execute_reply": "2022-09-06T16:20:42.773051Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep_example_df():\n",
    "    raster_example = monkey_defs.raster_example\n",
    "    raster_example_df = []\n",
    "    for session in raster_example:\n",
    "        path = root/session.split('_')[0]/session\n",
    "        df = monkey_defs.prep_general(dt.load_pyal_data(path))\n",
    "        df = pyal.restrict_to_interval(df, epoch_fun=monkey_defs.exec_epoch)\n",
    "        raster_example_df.append(df)\n",
    "    return raster_example_df\n",
    "\n",
    "@utility.report\n",
    "def plot_moneky_fr_raster(df,gs):\n",
    "    trial=12\n",
    "    axes = []\n",
    "    data = []\n",
    "\n",
    "    #example trial data for each target\n",
    "    for tar in range(monkey_defs.n_targets):\n",
    "        df_ = pyal.select_trials(df, df.target_id==tar)\n",
    "        data.append(df_.M1_rates[trial])\n",
    "    data = np.array(data)\n",
    "    vmin = np.amin(data, axis= (0,1))\n",
    "    vmax = np.amax(data, axis= (0,1))\n",
    "\n",
    "    for j,tarData in enumerate(data):\n",
    "        ax = fig.add_subplot(gs[j])\n",
    "        axes.append(ax)\n",
    "        tarData -= vmin\n",
    "        tarData /= (vmax - vmin)\n",
    "        ax.imshow(tarData.T, aspect='auto')\n",
    "        ax.tick_params('both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.set_title(r'$ \\rightarrow $', rotation=(360/monkey_defs.n_targets)*(j-3), pad=0.5)\n",
    "    axes[0].set_ylabel(f'Units ($n={tarData.shape[1]}$)')\n",
    "    return axes\n",
    "\n",
    "@utility.report\n",
    "def plot_moneky_vel_ex(df,gs):\n",
    "    trial=12\n",
    "    axes = []\n",
    "    for tar in range(monkey_defs.n_targets):\n",
    "        df_ = pyal.select_trials(df, df.target_id==tar)\n",
    "        data = df_.pos[trial]\n",
    "        data -= np.mean(data, axis=0, keepdims=True)\n",
    "        ax = fig.add_subplot(gs[tar])\n",
    "        axes.append(ax)\n",
    "        ax.plot(data[:,0], color='b', label='$X$')\n",
    "        # ax2 = ax.twinx()\n",
    "        # utility.phantom_axes(ax2)\n",
    "        ax.plot(data[:,1], color='r', label='$Y$')\n",
    "        ax.tick_params('both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    return axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36774a15-9858-4c69-8140-1b29bf384245",
   "metadata": {},
   "source": [
    "3D dynamics panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0ea7e3-7def-41da-9fb9-7d6deae34b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:20:42.774965Z",
     "iopub.status.busy": "2022-09-06T16:20:42.774863Z",
     "iopub.status.idle": "2022-09-06T16:20:42.780853Z",
     "shell.execute_reply": "2022-09-06T16:20:42.780546Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_monkey_pc_example(raster_example_df, gs):   \n",
    "    fig=gs.figure\n",
    "    \n",
    "    colors = utility.get_colors(8)\n",
    "    dfs=[]\n",
    "    axes=[]\n",
    "    for i,df in enumerate(raster_example_df):\n",
    "        rates = np.concatenate(df['M1_rates'].values, axis=0)\n",
    "        rates_model = PCA(n_components=10, svd_solver='full').fit(rates)\n",
    "        df_ = pyal.apply_dim_reduce_model(df, rates_model, 'M1_rates', '_pca');\n",
    "        dfs.append(df_)\n",
    "        ax = fig.add_subplot(gs[i], projection='3d',fc='None')\n",
    "        axes.append(ax)\n",
    "        for tar in range(monkey_defs.n_targets):\n",
    "            df__ = pyal.select_trials(df_, df_.target_id==tar)\n",
    "            ex = pyal.get_sig_by_trial(df__,'_pca')\n",
    "            ex = np.mean(ex, axis=2)[:,:3]\n",
    "            ax.plot(ex[:,0],ex[:,1],ex[:,2],color=colors[tar],lw=1)\n",
    "            ax.view_init(60,-47)\n",
    "\n",
    "    AllData = dt.get_data_array(raster_example_df, area='M1', model=10)\n",
    "    data1 = np.reshape(AllData[0,...], (-1,10))\n",
    "    data2 = np.reshape(AllData[1,...], (-1,10))\n",
    "    A,B,*_ = dt.canoncorr(data1,data2,fullReturn=True)\n",
    "    coef_ = [A,B]\n",
    "    for i,sessionData in enumerate(AllData):\n",
    "        ax = fig.add_subplot(gs[i+3], projection='3d',fc='None')\n",
    "        U, _, Vh = linalg.svd(coef_[i], full_matrices=False, compute_uv=True, overwrite_a=False, check_finite=False)\n",
    "        axes.append(ax)\n",
    "        for tar in range(8):\n",
    "            ex = np.mean(sessionData[tar,...], axis=0)\n",
    "            ex = ex @ U @ Vh\n",
    "            ax.plot(ex[:,0],ex[:,1],ex[:,2],color=colors[tar],lw=1)\n",
    "            ax.view_init(60,-47)\n",
    "\n",
    "    titles=[r'Monkey $C_L$ (\\textit{unaligned})',r'Monkey $M$ (\\textit{unaligned})',\n",
    "            r'Monkey $C_L$ (\\textit{aligned})',  r'Monkey $M$ (\\textit{aligned})']\n",
    "    labels = ['PC','PC','CC','CC']\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "        ax.set_xlabel(f'{labels[i]}1', labelpad=-15)\n",
    "        ax.set_ylabel(f'{labels[i]}2', labelpad=-15)\n",
    "        ax.set_zlabel(f'{labels[i]}3', labelpad=-15)\n",
    "        ax.set_title(titles[i], y=.9, loc='center')\n",
    "    \n",
    "    #======== add the arrow\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2], fc='None')\n",
    "    ax = utility.phantom_axes(ax)\n",
    "    ax.arrow(0,0,1,0,length_includes_head=True, width=.005, head_width=.015,head_length=.1, ec='k', fc='k')\n",
    "    ax.set_ylim([-.1,.1])\n",
    "    ax.set_xlim([-.5,1.1])\n",
    "    ax.text(0.5,0.01,'CCA', ha='center', va='bottom')\n",
    "    ax.text(0.5,-0.01,'(alignment)', ha='center', va='top')\n",
    "    \n",
    "    return axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f032e-2906-4d5e-9888-1140f80815af",
   "metadata": {},
   "source": [
    "CCA for the example sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a6550f-b95d-42fa-bc58-b6f5c4aa544f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:20:42.795939Z",
     "iopub.status.busy": "2022-09-06T16:20:42.795724Z",
     "iopub.status.idle": "2022-09-06T16:20:42.809837Z",
     "shell.execute_reply": "2022-09-06T16:20:42.809479Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_cca_for_ex(ax,):\n",
    "    defs = monkey_defs\n",
    "    raster_example = defs.raster_example\n",
    "    raster_example_df = []\n",
    "    for session in raster_example:\n",
    "        path = root/session.split('_')[0]/session\n",
    "        df = defs.prep_general(dt.load_pyal_data(path))\n",
    "        raster_example_df.append(df)\n",
    "    \n",
    "    df1, df2 = raster_example_df\n",
    "    AllData1 = dt.get_data_array(df1, defs.exec_epoch, area=defs.areas[2], model=defs.n_components)\n",
    "    AllData2 = dt.get_data_array(df2, defs.exec_epoch, area=defs.areas[2], model=defs.n_components)\n",
    "    _,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "    allCCs=[]\n",
    "    for sessionData1,sessionData2 in zip(AllData1,AllData2):\n",
    "        data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "        data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "        allCCs.append(dt.canoncorr(data1, data2))\n",
    "    allCCs = np.array(allCCs).T\n",
    "    \n",
    "    # lower bound\n",
    "    len_trial = int(np.round(np.diff(defs.WINDOW_exec)/defs.BIN_SIZE))\n",
    "    AllDataL1 = defs._get_data_array(df1, epoch_L=len_trial, area=defs.areas[2], model=defs.n_components)\n",
    "    AllDataL2 = defs._get_data_array(df2, epoch_L=len_trial, area=defs.areas[2], model=defs.n_components)\n",
    "    _,_, min_trials, min_time,_ = np.min((AllDataL1.shape,AllDataL2.shape),axis=0)\n",
    "    CCsL=[]\n",
    "    for sessionData1,sessionData2 in zip(AllDataL1,AllDataL2):\n",
    "        r = []\n",
    "        for n in range(params.n_iter * 10):\n",
    "            sessionData1_sh = params.rng.permutation(sessionData1,axis=0)\n",
    "            sessionData2_sh = params.rng.permutation(sessionData2,axis=0)\n",
    "            data1 = np.reshape(sessionData1_sh[:,:min_trials,:min_time,:], (-1,monkey_defs.n_components))\n",
    "            data2 = np.reshape(sessionData2_sh[:,:min_trials,:min_time,:], (-1,monkey_defs.n_components))\n",
    "            r.append(dt.canoncorr(data1, data2))\n",
    "        CCsL.append(r)\n",
    "    CCsL = np.array(CCsL)\n",
    "    CCsL = np.percentile(CCsL, 1, axis=1).T\n",
    "    \n",
    "    # upper bound\n",
    "    AllDataU = dt.get_data_array([df1,df2], monkey_defs.exec_epoch, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    n_shared_trial1 = AllDataU.shape[2]\n",
    "    trialList1 = np.arange(n_shared_trial1)\n",
    "    CCsU=[]\n",
    "    for session, sessionData in enumerate(AllDataU):\n",
    "        r = []\n",
    "        for n in range(params.n_iter * 10):\n",
    "            params.rng.shuffle(trialList1)\n",
    "            # non-overlapping randomised trials\n",
    "            trial1 = trialList1[:n_shared_trial1//2]\n",
    "            trial2 = trialList1[-(n_shared_trial1//2):]\n",
    "            data1 = np.reshape(sessionData[:,trial1,:,:], (-1,monkey_defs.n_components))\n",
    "            data2 = np.reshape(sessionData[:,trial2,:,:], (-1,monkey_defs.n_components))\n",
    "            r.append(dt.canoncorr(data1, data2))\n",
    "        CCsU.append(r)\n",
    "    CCsU = np.array(CCsU)\n",
    "    CCsU = np.percentile(CCsU, 99, axis=1).T\n",
    "\n",
    "    # plotting\n",
    "    x_ = np.arange(1,monkey_defs.n_components+1)\n",
    "    ax.plot(x_, allCCs, color=params.colors.MainCC, marker = 'o', label=f'Across monkeys')\n",
    "    ax.plot(x_, CCsU[:,0], color=params.colors.UpperCC, marker = '<', ls='--', label=f'Within monkey1')\n",
    "    ax.plot(x_, CCsU[:,1], marker = '<', ls='--', label=f'Within monkey2')\n",
    "    ax.plot(x_, CCsL, color=params.colors.LowerCC, marker = '>', ls=':', label=f'Control')\n",
    "\n",
    "\n",
    "    ax.set_ylim([-.05,1])\n",
    "    ax.set_xlim([.6,monkey_defs.n_components+.6])\n",
    "    ax.set_xlabel('Neural mode')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    # ax.set_title(f'{defs.areas[2]} Alignment')\n",
    "    ax.legend(loc=(.55,.67))\n",
    "    ax.set_ylabel('Canonical correlation')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_bounds([1,monkey_defs.n_components])\n",
    "    ax.spines['left'].set_bounds([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10159e45-a434-4695-b186-89f64ecf058c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "monkey population CCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fb936c-4ef3-4776-bd0f-bea0b5322a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:20:46.624932Z",
     "iopub.status.busy": "2022-09-06T16:20:46.624775Z",
     "iopub.status.idle": "2022-09-06T16:20:46.627639Z",
     "shell.execute_reply": "2022-09-06T16:20:46.627350Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def get_full_monkey_data():\n",
    "    full_list_MCx = []\n",
    "    for animal, sessionList in GoodDataList[monkey_defs.areas[2]].items():\n",
    "        if 'Mr' in animal:\n",
    "            continue  # to remove MrT\n",
    "        full_list_MCx.append((animal,sessionList))\n",
    "    full_list_MCx = [(animal,session) for animal,sessions in full_list_MCx for session in set(sessions)]\n",
    "    # load the DFs\n",
    "    allDFs_MCx = []\n",
    "    for animal, session in full_list_MCx:\n",
    "        path = root/animal/session\n",
    "        allDFs_MCx.append(monkey_defs.prep_general(dt.load_pyal_data(path)))\n",
    "\n",
    "    return full_list_MCx, allDFs_MCx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ab4f90-108f-4c22-a744-3a35db5b2038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:20:46.629040Z",
     "iopub.status.busy": "2022-09-06T16:20:46.628928Z",
     "iopub.status.idle": "2022-09-06T16:20:46.642138Z",
     "shell.execute_reply": "2022-09-06T16:20:46.641855Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_monkey_cca(ax, ax_hist, full_list_MCx, allDFs_MCx):\n",
    "    pairFileList1 = []\n",
    "    for I, (animal1,session1) in enumerate(full_list_MCx):\n",
    "        for J, (animal2,session2) in enumerate(full_list_MCx):\n",
    "            if J<=I or animal1 == animal2: continue  # to repetitions\n",
    "            if 'Chewie' in animal1 and 'Chewie' in animal2: continue \n",
    "            pairFileList1.append((I,J))\n",
    "\n",
    "    side1df = [allDFs_MCx[i] for i,_ in pairFileList1]\n",
    "    side2df = [allDFs_MCx[j] for _,j in pairFileList1]\n",
    "    AllData1 = dt.get_data_array(side1df, monkey_defs.exec_epoch, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    AllData2 = dt.get_data_array(side2df, monkey_defs.exec_epoch, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    _,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "    allCCs=[]\n",
    "    for sessionData1,sessionData2 in zip(AllData1,AllData2):\n",
    "        data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "        data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "        allCCs.append(dt.canoncorr(data1, data2))\n",
    "    allCCs = np.array(allCCs).T\n",
    "\n",
    "    # lower bound\n",
    "    len_trial = int(np.round(np.diff(monkey_defs.WINDOW_exec)/monkey_defs.BIN_SIZE))\n",
    "    single_FileList1 = []\n",
    "    for I, (animal1,session1) in enumerate(full_list_MCx):\n",
    "        for J, (animal2,session2) in enumerate(full_list_MCx):\n",
    "            if J<=I or animal1 == animal2: continue  # to repetitions\n",
    "            if 'Chewie' in animal1 and 'Chewie' in animal2: continue \n",
    "            single_FileList1.append((I,J))\n",
    "    n_iter = params.n_iter * 10\n",
    "    side1df = [allDFs_MCx[i] for i,_ in single_FileList1]\n",
    "    side2df = [allDFs_MCx[j] for _,j in single_FileList1]\n",
    "    AllData1 = monkey_defs._get_data_array(side1df, epoch_L=len_trial, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    AllData1_ = monkey_defs._get_data_array(side2df, epoch_L=len_trial, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    _,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData1_.shape),axis=0)\n",
    "\n",
    "    CCsL=[]\n",
    "    for sessionData1,sessionData2 in zip(AllData1,AllData1_):\n",
    "        r = []\n",
    "        for n in range(n_iter):\n",
    "            sessionData1_sh = params.rng.permutation(sessionData1,axis=0)\n",
    "            sessionData2_sh = params.rng.permutation(sessionData2,axis=0)\n",
    "\n",
    "            data1 = np.reshape(sessionData1_sh[:,:min_trials,:min_time,:], (-1,monkey_defs.n_components))\n",
    "            data2 = np.reshape(sessionData2_sh[:,:min_trials,:min_time,:], (-1,monkey_defs.n_components))\n",
    "            r.append(dt.canoncorr(data1, data2))\n",
    "        CCsL.append(r)\n",
    "    CCsL = np.array(CCsL)\n",
    "    CCsL = np.percentile(CCsL, 1, axis=1).T\n",
    "\n",
    "    # Upper bound\n",
    "    single_FileList1 = []\n",
    "    for I, _ in enumerate(full_list_MCx):\n",
    "        single_FileList1.append(I)\n",
    "    side1df = [allDFs_MCx[i] for i in single_FileList1]\n",
    "    AllData1 = dt.get_data_array(side1df, monkey_defs.exec_epoch, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    n_shared_trial1 = AllData1.shape[2]\n",
    "    trialList1 = np.arange(n_shared_trial1)\n",
    "    CCsU=[]\n",
    "    for session, sessionData in enumerate(AllData1):\n",
    "        r = []\n",
    "        for n in range(n_iter):\n",
    "            params.rng.shuffle(trialList1)\n",
    "            # non-overlapping randomised trials\n",
    "            trial1 = trialList1[:n_shared_trial1//2]\n",
    "            trial2 = trialList1[-(n_shared_trial1//2):]\n",
    "            data1 = np.reshape(sessionData[:,trial1,:,:], (-1,defs.n_components))\n",
    "            data2 = np.reshape(sessionData[:,trial2,:,:], (-1,defs.n_components))\n",
    "            r.append(dt.canoncorr(data1, data2))\n",
    "        CCsU.append(r)\n",
    "    CCsU = np.array(CCsU)\n",
    "    CCsU = np.percentile(CCsU, 99, axis=1).T\n",
    "\n",
    "    # plotting\n",
    "    x_ = np.arange(1,monkey_defs.n_components+1)\n",
    "    utility.shaded_errorbar(ax, x_, allCCs, color=params.colors.MainCC, marker = 'o')\n",
    "    utility.shaded_errorbar(ax, x_, CCsU, color=params.colors.UpperCC, marker = '<', ls='--')\n",
    "    utility.shaded_errorbar(ax, x_, CCsL, color=params.colors.LowerCC, marker = '>', ls=':')\n",
    "\n",
    "    ax.set_ylim([-.05,1])\n",
    "    ax.set_xlim([.6,monkey_defs.n_components+.6])\n",
    "    ax.set_xlabel('Neural mode')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylabel('Canonical correlation')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_bounds([1,monkey_defs.n_components])\n",
    "    ax.spines['left'].set_bounds([0,1])\n",
    "    ax.text(x=monkey_defs.n_components, y=1, s= f'$n={CCsL.shape[1]}$ pairs of sessions\\nacross $3$ monkeys',\n",
    "           ha='right', va='top', fontsize=mpl.rcParams['xtick.labelsize'])\n",
    "    \n",
    "    #plot the hist\n",
    "\n",
    "    bins = np.arange(0,1,0.05)\n",
    "    ax_hist.xaxis.set_visible(False)\n",
    "    ax_hist.set_facecolor('None')\n",
    "    ax_hist.spines['bottom'].set_visible(False)\n",
    "    ax_hist.spines['right'].set_visible(False)\n",
    "    ax_hist.spines['top'].set_visible(False)\n",
    "    ax_hist.spines['left'].set_bounds([0,1])\n",
    "    ax_hist.set_ylim([-.05,1])\n",
    "    ax_hist.hist(allCCs[:4,:].mean(axis=0), bins=bins, density=True, label=f'Across ($n={allCCs.shape[1]}$)',\n",
    "            color=params.colors.MainCC, alpha=.8, orientation='horizontal')\n",
    "    ax_hist.hist(CCsU[:4,:].mean(axis=0), bins=bins, density=True,label=f'Within ($n={CCsU.shape[1]}$)',\n",
    "            color=params.colors.UpperCC, alpha=.8, orientation='horizontal')\n",
    "    ax_hist.hist(CCsL[:4,:].mean(axis=0), bins=bins, density=True, label=f'Control ($n={CCsL.shape[1]}$)',\n",
    "            color=params.colors.LowerCC, alpha=.8, orientation='horizontal')\n",
    "\n",
    "    ax_hist.tick_params('y', direction='out')\n",
    "    ax_hist.set_yticklabels([])\n",
    "    ax_hist.legend(loc=(0,-.05))\n",
    "\n",
    "    #stats ###################################\n",
    "    allCCs_median = np.median(allCCs[:4,:].mean(axis=0))\n",
    "    CCsU_median = np.median(CCsU[:4,:].mean(axis=0))\n",
    "    CCsL_median = np.median(CCsL[:4,:].mean(axis=0))\n",
    "    allCCs_mean = allCCs[:4,:].mean(axis=0)\n",
    "    CCsU_mean = CCsU[:4,:].mean(axis=0)\n",
    "    CCsL_mean = CCsL[:4,:].mean(axis=0)\n",
    "\n",
    "    #calc stats\n",
    "    ##for paired stats\n",
    "    side1CCsU_mean = [CCsU_mean[i] for i,_ in pairFileList1]\n",
    "    side2CCsU_mean = [CCsU_mean[j] for _,j in pairFileList1]\n",
    "    allCCsU_mean = side1CCsU_mean + side2CCsU_mean\n",
    "        \n",
    "    compare_upper_stats = wilcoxon(np.tile(allCCs_mean,2), allCCsU_mean)\n",
    "    compare_lower_stats = wilcoxon(allCCs_mean, CCsL_mean)\n",
    "\n",
    "    ##for unpaired stats\n",
    "    # compare_upper_stats = mannwhitneyu(allCCs_mean, CCsU_mean)\n",
    "    # compare_lower_stats = mannwhitneyu(allCCs_mean, CCsL_mean)\n",
    "\n",
    "    print(\"Across vs within:\", compare_upper_stats)\n",
    "    print(\"Across vs control:\", compare_lower_stats)\n",
    "\n",
    "    if params.annotate_stats:\n",
    "        #annotate stats\n",
    "        xmin, xmax = ax_hist.get_xlim()\n",
    "        markerx = xmax+(xmax-xmin)*0.05\n",
    "        linex = xmax+(xmax-xmin)*0.15\n",
    "        textx = xmax+(xmax-xmin)*0.25\n",
    "        line_kwargs = dict(linewidth = 0.5, color = 'k')\n",
    "        text_kwargs = dict(ha='left', va='center')\n",
    "\n",
    "        ax_hist.scatter(markerx, allCCs_median, color = params.colors.MainCC, marker = '<')\n",
    "        ax_hist.scatter(markerx, CCsU_median, color = params.colors.UpperCC, marker = '<')\n",
    "        ax_hist.scatter(markerx, CCsL_median, color = params.colors.LowerCC, marker = '<')\n",
    "\n",
    "        ax_hist.plot([linex, linex], [allCCs_median, CCsU_median], **line_kwargs)\n",
    "        ax_hist.plot([linex, linex], [allCCs_median, CCsL_median], linestyle = '--', **line_kwargs)\n",
    "        \n",
    "        ax_hist.text(textx, (allCCs_median + CCsU_median)/2, dt.get_signif_annot(compare_upper_stats[1]), **text_kwargs)\n",
    "        ax_hist.text(textx, (allCCs_median + CCsL_median)/2, dt.get_signif_annot(compare_lower_stats[1]), **text_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145a731-d518-4b69-bc46-78ca617b9745",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "decoding for monkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0659f95f-f4a6-4333-8480-9fa7594ea14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:21:07.366520Z",
     "iopub.status.busy": "2022-09-06T16:21:07.366375Z",
     "iopub.status.idle": "2022-09-06T16:21:07.388180Z",
     "shell.execute_reply": "2022-09-06T16:21:07.387767Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "\n",
    "def plot_monkey_decoding(ax, allDFs, redo = False):\n",
    "    defs = monkey_defs\n",
    "\n",
    "    within_score = {}\n",
    "    aligned_score = {}\n",
    "    unaligned_score = {}\n",
    "    for i, df1 in enumerate(tqdm(allDFs)):\n",
    "        pathPickle = root / 'monkey-pickles' / f'{df1.session[0]}_within.p'\n",
    "\n",
    "        if os.path.exists(pathPickle) and not redo:\n",
    "            with open(pathPickle,\"rb\") as f:\n",
    "                within_score[df1.session[0]] = pickle.load(f)\n",
    "        else:\n",
    "            AllData, AllVel = defs.get_data_array_and_vel([df1], defs.exec_epoch_decode,\n",
    "                                                        area=defs.areas[2], n_components=defs.n_components)\n",
    "            # adding history\n",
    "            AllData = dt.add_history_to_data_array(AllData,defs.MAX_HISTORY)\n",
    "            AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "            AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "            AllData1 = AllData[0,...]\n",
    "            AllVel1 = AllVel[0,...]\n",
    "            *_,n_time,n_comp = AllData1.shape\n",
    "            # resizing\n",
    "            X1 = AllData1.reshape((-1,n_time,n_comp))\n",
    "            AllVel1 = AllVel1.reshape((-1,n_time,2))\n",
    "            \n",
    "            fold_score =[]\n",
    "            kf = KFold(n_splits=10)\n",
    "            for train_index, test_index in kf.split(X1[:,0,0]):\n",
    "                x_train, x_test = X1[train_index,...], X1[test_index,...]\n",
    "                y_train, y_test = AllVel1[train_index,...], AllVel1[test_index,...]\n",
    "\n",
    "                lstm_model = lstm.LSTMDecoder(input_dims=X1.shape[-1], output_dims=2)\n",
    "                lstm_model.fit(x_train=x_train, y_train=y_train)\n",
    "                lstm_model.predict(x_test, y_test)\n",
    "                fold_score.append(lstm_model.score)\n",
    "            fold_score = np.median(fold_score)\n",
    "            within_score[df1.session[0]] = fold_score\n",
    "\n",
    "            with open(pathPickle, 'wb') as f:\n",
    "                pickle.dump(within_score[df1.session[0]], f)\n",
    "                f.close()\n",
    "\n",
    "        aligned_score[df1.session[0]] = {}\n",
    "        unaligned_score[df1.session[0]] = {}\n",
    "        for j, df2 in enumerate(tqdm(allDFs)):\n",
    "            if j <= i: continue\n",
    "            if df1.monkey[0] == df2.monkey[0]: continue\n",
    "            if 'Chewie' in df1.monkey[0] and 'Chewie' in df2.monkey[0]: continue\n",
    "            alignedPickle = root / 'monkey-pickles' /  f'{df1.session[0]}-{df2.session[0]}_aligned.p'\n",
    "            unalignedPickle = root / 'monkey-pickles' /  f'{df1.session[0]}-{df2.session[0]}_unaligned.p'\n",
    "            if os.path.exists(alignedPickle) and os.path.exists(unalignedPickle) and not redo:\n",
    "                with open(alignedPickle,\"rb\") as f:\n",
    "                    aligned_score[df1.session[0]][df2.session[0]] = pickle.load(f)\n",
    "                    f.close()\n",
    "                with open(unalignedPickle,\"rb\") as f:\n",
    "                    unaligned_score[df1.session[0]][df2.session[0]] = pickle.load(f)\n",
    "                    f.close()\n",
    "            else:\n",
    "\n",
    "                AllData, AllVel = defs.get_data_array_and_vel([df1,df2],\n",
    "                                                            defs.exec_epoch_decode, area=defs.areas[2], n_components=defs.n_components)\n",
    "                # adding history\n",
    "                AllData = dt.add_history_to_data_array(AllData,defs.MAX_HISTORY)\n",
    "                AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "                AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "\n",
    "                AllData1 = AllData[0,...]\n",
    "                AllData2 = AllData[1,...]\n",
    "                AllVel1 = AllVel[0,...]\n",
    "                AllVel2 = AllVel[1,...]\n",
    "                # resizing\n",
    "                *_,n_time,n_comp = AllData1.shape\n",
    "\n",
    "                X1 = AllData1.reshape((-1,n_comp))\n",
    "                X2 = AllData2.reshape((-1,n_comp))\n",
    "                AllVel2 = AllVel2.reshape((-1,n_time,2))\n",
    "                AllVel1 = AllVel1.reshape((-1,n_time,2))\n",
    "\n",
    "                # train the aligned\n",
    "                *_,U,V = dt.canoncorr(X1, X2, fullReturn=True)\n",
    "                U = U.reshape((-1,n_time,n_comp))\n",
    "                V = V.reshape((-1,n_time,n_comp))\n",
    "                X1 = X1.reshape((-1,n_time,n_comp))\n",
    "                X2 = X2.reshape((-1,n_time,n_comp))\n",
    "\n",
    "                lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=2)\n",
    "                lstm_model.fit(x_train=U, y_train=AllVel1)\n",
    "                lstm_model.predict(V, AllVel2)\n",
    "                aligned_score[df1.session[0]][df2.session[0]]=lstm_model.score.mean()\n",
    "                with open(alignedPickle, 'wb') as f:\n",
    "                    pickle.dump(lstm_model.score.mean(), f)\n",
    "                    f.close()\n",
    "                #================================\n",
    "                # Unaligned\n",
    "                lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=2)\n",
    "                lstm_model.fit(x_train=X1, y_train=AllVel1)\n",
    "                lstm_model.predict(X2, AllVel2)\n",
    "                unaligned_score[df1.session[0]][df2.session[0]]=lstm_model.score.mean()\n",
    "                with open(unalignedPickle, 'wb') as f:\n",
    "                    pickle.dump(lstm_model.score.mean(), f)\n",
    "                    f.close()\n",
    "\n",
    "#======================== PLOTTING\n",
    "    pop_within = np.array(list(within_score.values()))\n",
    "    pop_aligned = np.array([val for key in aligned_score for val in aligned_score[key].values()])\n",
    "    pop_unaligned = np.array([val for key in unaligned_score for val in unaligned_score[key].values()])\n",
    "\n",
    "    ax.errorbar(1, pop_aligned.mean(), np.std(pop_aligned), label='Across\\n' r'(\\textit{aligned})',\n",
    "                color=params.colors.MainCC, fmt='-o', capsize=1.5)    \n",
    "    ax.errorbar(0, pop_unaligned.mean(), np.std(pop_unaligned), label='Across\\n' r'(\\textit{unaligned})',\n",
    "                color=params.colors.LowerCC, fmt='-o', capsize=1.5)\n",
    "    ax.errorbar(2, pop_within.mean(), np.std(pop_within), label='Within',\n",
    "                color=params.colors.UpperCC, fmt='-o', capsize=1.5)\n",
    "\n",
    "    unal_vals = []\n",
    "    al_vals = []\n",
    "    wi_vals = []\n",
    "    for file1, nested_dict in aligned_score.items():\n",
    "        wi_val1 = within_score[file1]\n",
    "        for file2, al_val in nested_dict.items():\n",
    "            wi_val2 = within_score[file2]\n",
    "            unal_val = unaligned_score[file1][file2]\n",
    "            ax.plot([0,1,2], [unal_val, al_val, wi_val1],\n",
    "                    color='gray', lw=.2, zorder=6, marker = 'o', ms=.1, alpha=.2)\n",
    "            ax.plot([1,2], [al_val, wi_val2],\n",
    "                    color='gray', lw=.2, zorder=6, marker = 'o', ms=.1, alpha=.2)\n",
    "\n",
    "            #for stats\n",
    "            unal_vals.append(unal_val)\n",
    "            al_vals.append(al_val)\n",
    "            wi_vals.append(wi_val1)\n",
    "            wi_vals.append(wi_val2)\n",
    "    \n",
    "    ax.set_xlim([-0.2,2.2])\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(['Across\\n' r'(\\textit{unaligned})',\n",
    "                        'Across\\n' r'(\\textit{aligned})',\n",
    "                        'Within'])\n",
    "    ax.set_ylabel('Prediction accuracy ($R^2$)')\n",
    "    ax.set_ylim([-.05,1])\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_bounds([0,2])\n",
    "    ax.spines['left'].set_bounds([0,1])\n",
    "\n",
    "    #stats ########################################\n",
    "    #calc stats\n",
    "    ##for paired stats\n",
    "    compare_upper_stats = wilcoxon(np.repeat(al_vals,2), wi_vals)\n",
    "    compare_lower_stats = wilcoxon(al_vals, unal_vals)\n",
    "\n",
    "    print(\"Across vs within:\", compare_upper_stats)\n",
    "    print(\"Across vs control:\", compare_lower_stats)\n",
    "\n",
    "    #annotate stats\n",
    "    # if params.annotate_stats:\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    liney = ymax*0.95\n",
    "    texty = ymax*1\n",
    "    line_kwargs = dict(linewidth = 0.5, color = 'k')\n",
    "    text_kwargs = dict(ha='left', va='center')\n",
    "\n",
    "    ax.plot([0,1], [liney, liney], **line_kwargs)\n",
    "    ax.plot([1,2], [liney, liney], linestyle = '--', **line_kwargs)\n",
    "    \n",
    "    ax.text(0.5, texty, dt.get_signif_annot(compare_upper_stats[1]), **text_kwargs)\n",
    "    ax.text(1.5, texty, dt.get_signif_annot(compare_lower_stats[1]), **text_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6806511-6197-45b5-beb6-316a050c9c83",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Mouse CCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ceccd6-a508-4bef-84e7-9cffa87aed00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:21:07.665439Z",
     "iopub.status.busy": "2022-09-06T16:21:07.665226Z",
     "iopub.status.idle": "2022-09-06T16:21:07.669946Z",
     "shell.execute_reply": "2022-09-06T16:21:07.669660Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def get_full_mouse_data():\n",
    "    defs = mouse_defs\n",
    "    \n",
    "    animalList = ['mouse-data']\n",
    "    animalFiles = []\n",
    "    for animal in animalList:\n",
    "        animalFiles.extend(utility.find_file(root / animal, 'mat'))\n",
    "\n",
    "    AllDFs=[]\n",
    "    for fname in animalFiles:\n",
    "        df = dt.load_pyal_data(fname)\n",
    "        df['mouse'] = fname.split(os.sep)[-1][fname.split(os.sep)[-1].find('WR'):].split('_')[0]\n",
    "        df['file'] = fname.split(os.sep)[-1]\n",
    "        df = defs.prep_general_mouse(df)\n",
    "        AllDFs.append(df)\n",
    "\n",
    "    allDFs_M1 = []\n",
    "    for df in AllDFs:\n",
    "        if 'M1_rates' in df.columns:\n",
    "            allDFs_M1.append(df)\n",
    "\n",
    "    allDFs_Str = []\n",
    "    for df in AllDFs:\n",
    "        if 'Str_rates' in df.columns:\n",
    "            allDFs_Str.append(df)\n",
    "            \n",
    "    return allDFs_M1, allDFs_Str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7231f59-8b48-4f87-a746-4a753c32730d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:21:07.671441Z",
     "iopub.status.busy": "2022-09-06T16:21:07.671332Z",
     "iopub.status.idle": "2022-09-06T16:21:07.782167Z",
     "shell.execute_reply": "2022-09-06T16:21:07.781735Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_mouse_cca(ax, ax_hist, allDFs_M1):\n",
    "    defs = mouse_defs\n",
    "    \n",
    "    pairFileList1 = []\n",
    "    for I, df1 in enumerate(allDFs_M1):\n",
    "        for J, (df2) in enumerate(allDFs_M1):\n",
    "            if J<=I or df1.mouse[0] == df2.mouse[0]: continue  # repetitions\n",
    "            pairFileList1.append((I,J))\n",
    "    side1df = [allDFs_M1[i] for i,_ in pairFileList1]\n",
    "    side2df = [allDFs_M1[j] for _,j in pairFileList1]\n",
    "    AllData1 = dt.get_data_array(side1df, defs.exec_epoch, area=defs.areas[0], model=defs.n_components)\n",
    "    AllData2 = dt.get_data_array(side2df, defs.exec_epoch, area=defs.areas[0], model=defs.n_components)\n",
    "    _,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "    allCCs=[]\n",
    "    for sessionData1,sessionData2 in zip(AllData1,AllData2):\n",
    "        data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "        data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "        allCCs.append(dt.canoncorr(data1, data2))\n",
    "    allCCs = np.array(allCCs).T\n",
    "\n",
    "    # upper bound\n",
    "    AllData1 = dt.get_data_array(allDFs_M1, defs.exec_epoch, area=defs.areas[0], model=defs.n_components)\n",
    "    n_iter = params.n_iter * 10\n",
    "    n_shared_trial1 = AllData1.shape[2]\n",
    "    trialList1 = np.arange(n_shared_trial1)\n",
    "    CCsU=[]\n",
    "    for sessionData in AllData1:\n",
    "        r = []\n",
    "        for n in range(n_iter):\n",
    "            params.rng.shuffle(trialList1)\n",
    "            # non-overlapping randomised trials\n",
    "            trial1 = trialList1[:n_shared_trial1//2]\n",
    "            trial2 = trialList1[-(n_shared_trial1//2):]\n",
    "            data1 = np.reshape(sessionData[:,trial1,:,:], (-1,defs.n_components))\n",
    "            data2 = np.reshape(sessionData[:,trial2,:,:], (-1,defs.n_components))\n",
    "            r.append(dt.canoncorr(data1, data2))\n",
    "        CCsU.append(r)\n",
    "    CCsU = np.array(CCsU)\n",
    "    CCsU = np.percentile(CCsU, 99, axis=1).T\n",
    "\n",
    "    # lower bound\n",
    "    pairFileList1 = []\n",
    "    for I, df1 in enumerate(allDFs_M1):\n",
    "        for J, df2 in enumerate(allDFs_M1):\n",
    "            if J<=I or df1.mouse[0] == df2.mouse[0]: continue  # repetitions\n",
    "            pairFileList1.append((I,J))\n",
    "    side1df = [allDFs_M1[i] for i,_ in pairFileList1]\n",
    "    side2df = [allDFs_M1[j] for _,j in pairFileList1]\n",
    "    len_trial = int(np.round(np.diff(defs.WINDOW_exec)/defs.BIN_SIZE))\n",
    "\n",
    "    AllData1 = dt.get_data_array(side1df, area=defs.areas[0], model=defs.n_components)\n",
    "    AllData2 = dt.get_data_array(side2df, area=defs.areas[0], model=defs.n_components)\n",
    "    _,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "\n",
    "    CCsL=[]\n",
    "    for sessionData1,sessionData2 in zip(AllData1,AllData2):\n",
    "        r = []\n",
    "        for n in range(n_iter):\n",
    "            sessionData1_sh = params.rng.permutation(sessionData1,axis=0)\n",
    "            sessionData2_sh = params.rng.permutation(sessionData2,axis=0)\n",
    "            time_idx = params.rng.integers(min_time-len_trial)\n",
    "\n",
    "            data1 = np.reshape(sessionData1_sh[:,:min_trials,time_idx:time_idx+len_trial,:], (-1,defs.n_components))\n",
    "            data2 = np.reshape(sessionData2_sh[:,:min_trials,time_idx:time_idx+len_trial,:], (-1,defs.n_components))\n",
    "            r.append(dt.canoncorr(data1, data2))\n",
    "        CCsL.append(r)\n",
    "    CCsL = np.array(CCsL)\n",
    "    CCsL = np.percentile(CCsL, 1, axis=1).T\n",
    "\n",
    "\n",
    "    #====================================PLOTTING\n",
    "    \n",
    "    x_ = np.arange(1,defs.n_components+1)\n",
    "    utility.shaded_errorbar(ax, x_, allCCs, color=params.colors.MainCC, marker = 'o')\n",
    "    utility.shaded_errorbar(ax, x_, CCsU, color=params.colors.UpperCC, marker = '<', ls='--')\n",
    "    utility.shaded_errorbar(ax, x_, CCsL, color=params.colors.LowerCC, marker = '>', ls=':')\n",
    "\n",
    "    ax.set_ylim([-.05,1])\n",
    "    ax.set_xlim([.6,defs.n_components+.6])\n",
    "    ax.set_xlabel('Neural mode')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylabel('Canonical correlation')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_bounds([1,defs.n_components])\n",
    "    ax.spines['left'].set_bounds([0,1])\n",
    "    ax.text(x=defs.n_components, y=1, s= f'$n={CCsL.shape[1]}$ pairs of sessions\\nacross $4$ mice', ha='right', va='top', fontsize=mpl.rcParams['xtick.labelsize'])\n",
    "\n",
    "    #plot the hist\n",
    "\n",
    "    bins = np.arange(0,1,0.05)\n",
    "    ax_hist.xaxis.set_visible(False)\n",
    "    ax_hist.set_facecolor('None')\n",
    "    ax_hist.spines['bottom'].set_visible(False)\n",
    "    ax_hist.spines['right'].set_visible(False)\n",
    "    ax_hist.spines['top'].set_visible(False)\n",
    "    ax_hist.spines['left'].set_bounds([0,1])\n",
    "    ax_hist.set_ylim([-.05,1])\n",
    "    ax_hist.hist(allCCs[:4,:].mean(axis=0), bins=bins, density=True, label=f'($n={allCCs.shape[1]}$)',\n",
    "            color=params.colors.MainCC, alpha=.8, orientation='horizontal')\n",
    "    ax_hist.hist(CCsU[:4,:].mean(axis=0), bins=bins, density=True,label=f'($n={CCsU.shape[1]}$)',\n",
    "            color=params.colors.UpperCC, alpha=.8, orientation='horizontal')\n",
    "    ax_hist.hist(CCsL[:4,:].mean(axis=0), bins=bins, density=True, label=f'($n={CCsL.shape[1]}$)',\n",
    "            color=params.colors.LowerCC, alpha=.8, orientation='horizontal')\n",
    "    \n",
    "    ax_hist.tick_params('y', direction='out')\n",
    "    ax_hist.set_yticklabels([])\n",
    "    ax_hist.legend(loc=(0,-0.05))\n",
    "\n",
    "    #stats ###########################\n",
    "    allCCs_median = np.median(allCCs[:4,:].mean(axis=0))\n",
    "    CCsU_median = np.median(CCsU[:4,:].mean(axis=0))\n",
    "    CCsL_median = np.median(CCsL[:4,:].mean(axis=0))\n",
    "    allCCs_mean = allCCs[:4,:].mean(axis=0)\n",
    "    CCsU_mean = CCsU[:4,:].mean(axis=0)\n",
    "    CCsL_mean = CCsL[:4,:].mean(axis=0)\n",
    "\n",
    "    #calc stats\n",
    "    ##for paired stats\n",
    "    side1CCsU_mean = [CCsU_mean[i] for i,_ in pairFileList1]\n",
    "    side2CCsU_mean = [CCsU_mean[j] for _,j in pairFileList1]\n",
    "    allCCsU_mean = side1CCsU_mean + side2CCsU_mean\n",
    "        \n",
    "    compare_upper_stats = wilcoxon(np.tile(allCCs_mean,2), allCCsU_mean)\n",
    "    compare_lower_stats = wilcoxon(allCCs_mean, CCsL_mean)\n",
    "\n",
    "    ##for unpaired stats\n",
    "    # compare_upper_stats = mannwhitneyu(allCCs_mean, CCsU_mean)\n",
    "    # compare_lower_stats = mannwhitneyu(allCCs_mean, CCsL_mean)\n",
    "\n",
    "    print(\"Across vs within:\", compare_upper_stats)\n",
    "    print(\"Across vs control:\", compare_lower_stats)\n",
    "\n",
    "    #annotate stats\n",
    "    if params.annotate_stats:\n",
    "        xmin, xmax = ax_hist.get_xlim()\n",
    "        markerx = xmax+(xmax-xmin)*0.05\n",
    "        linex = xmax+(xmax-xmin)*0.15\n",
    "        textx = xmax+(xmax-xmin)*0.25\n",
    "        line_kwargs = dict(linewidth = 0.5, color = 'k')\n",
    "        text_kwargs = dict(ha='left', va='center')\n",
    "\n",
    "        ax_hist.scatter(markerx, allCCs_median, color = params.colors.MainCC, marker = '<')\n",
    "        ax_hist.scatter(markerx, CCsU_median, color = params.colors.UpperCC, marker = '<')\n",
    "        ax_hist.scatter(markerx, CCsL_median, color = params.colors.LowerCC, marker = '<')\n",
    "\n",
    "        ax_hist.plot([linex, linex], [allCCs_median, CCsU_median], **line_kwargs)\n",
    "        ax_hist.plot([linex, linex], [allCCs_median, CCsL_median], linestyle = '--', **line_kwargs)\n",
    "    \n",
    "        ax_hist.text(textx, (allCCs_median + CCsU_median)/2, dt.get_signif_annot(compare_upper_stats[1]), **text_kwargs)\n",
    "        ax_hist.text(textx, (allCCs_median + CCsL_median)/2, dt.get_signif_annot(compare_lower_stats[1]), **text_kwargs)\n",
    "    print(allCCs.shape, CCsU.shape)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753ee67-169e-4978-b9de-b24afb791bdb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "plot the behavioural vs CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2367e412-afd3-4b49-8228-d524420c6ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:21:16.604886Z",
     "iopub.status.busy": "2022-09-06T16:21:16.604597Z",
     "iopub.status.idle": "2022-09-06T16:21:16.626256Z",
     "shell.execute_reply": "2022-09-06T16:21:16.625955Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_monkey_cca_corr(ax, allDFs_MCx):\n",
    "\n",
    "    #get behavioral correlation for paired reaches\n",
    "    try:\n",
    "        os.chdir(params.repoPath / 'monkey')\n",
    "        %run \"_monkey-corr.ipynb\"\n",
    "    finally:\n",
    "        os.chdir(NBPath)\n",
    "    \n",
    "    across_corrs_monkeys = trim_across_monkey_corr(allDFs_MCx)\n",
    "\n",
    "    #get pairs of sessions\n",
    "    pairFileList_monkeys = []\n",
    "    for I, df1 in enumerate(allDFs_MCx):\n",
    "        for J, df2 in enumerate(allDFs_MCx):\n",
    "            if J<=I or df1.monkey[0] == df2.monkey[0]: continue  # to repetitions\n",
    "            if 'Chewie' in df1.monkey[0] and 'Chewie' in df2.monkey[0]: continue\n",
    "            pairFileList_monkeys.append((I,J))\n",
    "    \n",
    "    #get data for neural modes\n",
    "    side1df = [allDFs_MCx[i] for i,_ in pairFileList_monkeys]\n",
    "    side2df = [allDFs_MCx[j] for _,j in pairFileList_monkeys]\n",
    "    AllData1_monkey = dt.get_data_array(side1df, monkey_defs.exec_epoch, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    AllData2_monkey = dt.get_data_array(side2df, monkey_defs.exec_epoch, area=monkey_defs.areas[2], model=monkey_defs.n_components)\n",
    "    _,_, min_trials_monkey, min_time_monkey,_ = np.min((AllData1_monkey.shape,AllData2_monkey.shape),axis=0)\n",
    "\n",
    "    CC_corr_monkey=[]\n",
    "    #for each pair of sessions across monkeys\n",
    "    for i, (sessionData1,sessionData2) in enumerate(zip(AllData1_monkey,AllData2_monkey)):\n",
    "        data1 = np.reshape(sessionData1[:,:min_trials_monkey,:min_time_monkey,:], (-1,monkey_defs.n_components))\n",
    "        data2 = np.reshape(sessionData2[:,:min_trials_monkey,:min_time_monkey,:], (-1,monkey_defs.n_components))\n",
    "        k,l = pairFileList_monkeys[i]\n",
    "\n",
    "        #get behavioral correlation\n",
    "        behav = np.array(across_corrs_monkeys[allDFs_MCx[k].session[0]][allDFs_MCx[l].session[0]])\n",
    "        behav = behav[behav>params.Behav_corr_TH]\n",
    "\n",
    "        #perform CCA\n",
    "        CC_corr_monkey.append((dt.canoncorr(data1, data2)[:4].mean() , np.mean(behav)))\n",
    "    CC_corr_monkey = np.array(CC_corr_monkey)\n",
    "    \n",
    "    #plotting\n",
    "    ax.scatter(CC_corr_monkey[:,1],CC_corr_monkey[:,0], color=params.colors.MonkeyPts, label='Monkeys', zorder=0)\n",
    "    ax.set_xlabel('Behavioural correlation')\n",
    "    ax.set_ylabel('Canonical correlation')\n",
    "    ax.set_ylim([.53,.85])\n",
    "    ax.spines['left'].set_bounds([.55,.85])\n",
    "    ax.set_xlim([.69,.95])\n",
    "    ax.spines['bottom'].set_bounds([.7,.95])\n",
    "    ax.legend(loc=(0,.8))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('$%0.2f$'))\n",
    "\n",
    "    return CC_corr_monkey[:,1], CC_corr_monkey[:,0]\n",
    "    \n",
    "@utility.report\n",
    "def plot_mouse_cca_corr(ax, AllDFs):\n",
    "    try:\n",
    "        os.chdir(params.repoPath / 'mouse')\n",
    "        %run \"_mouse-corr.ipynb\"\n",
    "    finally:\n",
    "        os.chdir(NBPath)\n",
    "        \n",
    "    across_corrs_mice = trim_across_mouse_corr (AllDFs)\n",
    "    \n",
    "    pairFileList_mice = []\n",
    "    for I, df1 in enumerate(AllDFs):\n",
    "        for J, (df2) in enumerate(AllDFs):\n",
    "            if J<=I or df1.mouse[0] == df2.mouse[0]: continue  # repetitions\n",
    "            pairFileList_mice.append((I,J))\n",
    "\n",
    "    side1df = [AllDFs[i] for i,_ in pairFileList_mice]\n",
    "    side2df = [AllDFs[j] for _,j in pairFileList_mice]\n",
    "    AllData1_mice = dt.get_data_array(side1df, mouse_defs.exec_epoch, area=mouse_defs.areas[0], model=mouse_defs.n_components)\n",
    "    AllData2_mice = dt.get_data_array(side2df, mouse_defs.exec_epoch, area=mouse_defs.areas[0], model=mouse_defs.n_components)\n",
    "    _,_, min_trials_mice, min_time_mice,_ = np.min((AllData1_mice.shape,AllData2_mice.shape),axis=0)\n",
    "\n",
    "    CC_corr_mice=[]\n",
    "    for i, (sessionData1,sessionData2) in enumerate(zip(AllData1_mice,AllData2_mice)):\n",
    "        data1 = np.reshape(sessionData1[:,:min_trials_mice,:min_time_mice,:], (-1,mouse_defs.n_components))\n",
    "        data2 = np.reshape(sessionData2[:,:min_trials_mice,:min_time_mice,:], (-1,mouse_defs.n_components))\n",
    "        k,l = pairFileList_mice[i]\n",
    "        behav = np.array(across_corrs_mice[AllDFs[k].file[0]][AllDFs[l].file[0]])\n",
    "        behav = behav[behav>params.Behav_corr_TH]\n",
    "        CC_corr_mice.append((dt.canoncorr(data1, data2)[:4].mean() , np.mean(behav)))\n",
    "    CC_corr_mice = np.array(CC_corr_mice)\n",
    "\n",
    "    #plotting\n",
    "    ax.scatter(CC_corr_mice[:,1],CC_corr_mice[:,0],color=params.colors.MousePts, label='Mice', zorder=1)\n",
    "\n",
    "    return CC_corr_mice[:,1],CC_corr_mice[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1d836-1d1b-46d2-ab2d-e6d425feada1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "plot the within session trajectory correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f99964-9dbd-4988-8f35-aa1502597fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:21:43.244510Z",
     "iopub.status.busy": "2022-09-06T16:21:43.244382Z",
     "iopub.status.idle": "2022-09-06T16:21:43.251205Z",
     "shell.execute_reply": "2022-09-06T16:21:43.250851Z"
    }
   },
   "outputs": [],
   "source": [
    "@utility.report\n",
    "def plot_traj_corr(ax, allDFs_MCx, AllDFs):\n",
    "    try:\n",
    "        os.chdir(params.repoPath / 'monkey')\n",
    "        %run \"_monkey-corr.ipynb\"\n",
    "        os.chdir(params.repoPath / 'mouse')\n",
    "        %run \"_mouse-corr.ipynb\"\n",
    "    finally:\n",
    "        os.chdir(NBPath)\n",
    "\n",
    "    within_corrs_monkeys = trim_within_monkey_corr (allDFs_MCx)\n",
    "    within_corrs_mice = trim_within_mouse_corr (AllDFs)\n",
    "\n",
    "    # plotting\n",
    "    \n",
    "    w_mice = list(within_corrs_mice.values())\n",
    "    w_mice = np.array([l for L in w_mice for l in L])\n",
    "    w_monkey = list(within_corrs_monkeys.values())\n",
    "    w_monkey = np.array([l for L in w_monkey for l in L])\n",
    "    ax.hist(w_mice,   density=True,alpha=.8,color=params.colors.MousePts, label=r'Mice')\n",
    "    ax.hist(w_monkey, density=True,alpha=.8,color=params.colors.MonkeyPts, label=r'Monkeys')\n",
    "    ax.axvline(w_mice.mean(), color=params.colors.MousePts, zorder=0)\n",
    "    ax.axvline(w_monkey.mean(), color=params.colors.MonkeyPts, zorder=0)\n",
    "    \n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([0,1])\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.tick_params(axis='x', direction='in')\n",
    "    ax.set_ylabel('Probability\\ndensity')\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_facecolor('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078eb21-79b2-4e9a-96be-f7cd141f9ed2",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "Plot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfde11e9-58cf-43f9-b95c-a132acb86d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T16:21:44.246803Z",
     "iopub.status.busy": "2022-09-06T16:21:44.246668Z",
     "iopub.status.idle": "2022-09-06T16:26:10.016094Z",
     "shell.execute_reply": "2022-09-06T16:26:10.015620Z"
    }
   },
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "    %matplotlib inline\n",
    "    figsize=params.LargeFig\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    \n",
    "   \n",
    "\n",
    "    ##########################################\n",
    "    # 1: schematics\n",
    "    gs1   =utility.add_gridspec_abs(fig, nrows=1, ncols=1, left=0, \n",
    "                                    bottom=figsize[1]-params.panels.schmatic[1], \n",
    "                                    width=params.panels.schmatic[0], \n",
    "                                    height=params.panels.schmatic[1])\n",
    "    ax1   =fig.add_subplot(gs1[0])\n",
    "    ax1 = utility.phantom_axes(ax1)\n",
    "    ax1.set_facecolor([0,0,0,0])\n",
    "\n",
    "\n",
    "    ##########################################\n",
    "    # 2: Raster\n",
    "    gs2_1 = utility.add_gridspec_abs(fig, nrows=1, ncols=monkey_defs.n_targets,\n",
    "                                     left=params.panels.schmatic[0],\n",
    "                                     bottom=figsize[1]-params.panels.schmatic[1]+params.panels.velocity[1],\n",
    "                                     width=params.panels.raster[0], \n",
    "                                     height=params.panels.raster[1])\n",
    "    gs2_2 = utility.add_gridspec_abs(fig, nrows=1, ncols=monkey_defs.n_targets,\n",
    "                                     right=figsize[0],\n",
    "                                     top=figsize[1],\n",
    "                                     width=params.panels.raster[0], \n",
    "                                     height=params.panels.raster[1])\n",
    "    \n",
    "    gs2_3 = utility.add_gridspec_abs(fig, nrows=1, ncols=monkey_defs.n_targets,\n",
    "                                     left=params.panels.schmatic[0],\n",
    "                                     bottom=figsize[1]-params.panels.schmatic[1],\n",
    "                                     width=params.panels.raster[0], \n",
    "                                     height=params.panels.velocity[1])\n",
    "    gs2_4 = utility.add_gridspec_abs(fig, nrows=1, ncols=monkey_defs.n_targets,\n",
    "                                     right=figsize[0],\n",
    "                                     top=figsize[1]-params.panels.raster[1],\n",
    "                                     width=params.panels.raster[0], \n",
    "                                     height=params.panels.velocity[1])\n",
    "\n",
    "    \n",
    "    raster_example_df = prep_example_df()\n",
    "    \n",
    "    axes2_1 = plot_moneky_fr_raster(raster_example_df[0], gs2_1)\n",
    "    axes2_2 = plot_moneky_fr_raster(raster_example_df[1], gs2_2)\n",
    "    utility.phantom_axes(fig.add_subplot(gs2_1[:])).set_title('Monkey $C_L$', pad=8)\n",
    "    utility.phantom_axes(fig.add_subplot(gs2_2[:])).set_title('Monkey $M$', pad=8)\n",
    "    \n",
    "    axes2_3 = plot_moneky_vel_ex(raster_example_df[0], gs2_3)\n",
    "    axes2_4 = plot_moneky_vel_ex(raster_example_df[1], gs2_4)\n",
    "\n",
    "    axes2_3[0].set_ylabel('Position\\n(centred)')\n",
    "    axes2_3[0].set_xlabel('Time relative to movement onset',loc='left')\n",
    "    X_line = mlines.Line2D([], [], color='blue', label='$X$')\n",
    "    Y_line = mlines.Line2D([], [], color='red', label='$Y$')\n",
    "    axes2_4[-1].legend(handles=[X_line, Y_line], loc=(1.1,.1))\n",
    "        \n",
    "    gs2_c = utility.add_gridspec_abs(fig, nrows=1, ncols=1, \n",
    "                                     height=params.panels.raster[1]-.15, \n",
    "                                     width=.1, \n",
    "                                     left=figsize[0]+.2, \n",
    "                                     bottom=figsize[1]-params.panels.schmatic[1]+params.panels.velocity[1])\n",
    "    cax2 = fig.add_subplot(gs2_c[:])\n",
    "    fig.colorbar(cm.ScalarMappable(),cax=cax2, ticks=(0,1),drawedges=False)\n",
    "    cax2.set_title('Normalised\\nfiring rate')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    # 3: 3D projections\n",
    "    gs3   =utility.add_gridspec_abs(fig, nrows=1, ncols=5, left=0, \n",
    "                                    bottom=figsize[1]-params.panels.schmatic[1]-params.panels.proj_3d_align[1]-.3,\n",
    "                                    width=params.panels.proj_3d_align[0], \n",
    "                                    height=params.panels.proj_3d_align[1])\n",
    "\n",
    "    \n",
    "    axes3 = plot_monkey_pc_example(raster_example_df, gs3)\n",
    "    \n",
    "    \n",
    "    gs3_c = utility.add_gridspec_abs(fig, nrows=1, ncols=1, left=0,\n",
    "                                    bottom=(axes3[0].get_position().y0+axes3[0].get_position().y1)/2*figsize[1],\n",
    "                                    width=.2, height=0.2)\n",
    "    cax3 = fig.add_subplot(gs3_c[0],zorder=10)\n",
    "\n",
    "    utility.plot_targets(cax3,3)\n",
    "    cax3.set_xlim(np.array(cax3.get_xlim())*1.15)\n",
    "    cax3.set_ylim(np.array(cax3.get_ylim())*1.15)\n",
    "\n",
    "    \n",
    "    ##########################################\n",
    "    # 4: CCA plot for the example animals\n",
    "    gs4   =utility.add_gridspec_abs(fig, nrows=1, ncols=1,\n",
    "                                    left=0,\n",
    "                                    bottom=gs3.bottom*figsize[1]-params.panels.cca[1]-.3, \n",
    "                                    width=params.panels.cca[0],\n",
    "                                    height=params.panels.cca[1])\n",
    "\n",
    "    ax4 = fig.add_subplot(gs4[0])\n",
    "    \n",
    "    plot_cca_for_ex(ax4)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    # 5: CCA plot for population\n",
    "    gs5 = fig.add_gridspec(nrows=1, ncols=2,  width_ratios=(params.panels.cca[0],params.panels.cca_hist[0]-params.panels.cca[0]),\n",
    "                           left=gs4.right+(.7/figsize[0]),  # .7\" offset\n",
    "                           right=gs4.right+ (.7/figsize[0]) + params.panels.cca_hist[0]/figsize[0],\n",
    "                           bottom=gs4.bottom,\n",
    "                           top=gs4.top,\n",
    "                           wspace=0)\n",
    "\n",
    "    ax5 = fig.add_subplot(gs5[0])\n",
    "    ax5_ = fig.add_subplot(gs5[1])\n",
    "\n",
    "    full_list_MCx, allDFs_MCx = get_full_monkey_data()\n",
    "    \n",
    "    plot_monkey_cca(ax5,ax5_, full_list_MCx, allDFs_MCx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    # 6: Decoding for monkeys\n",
    "    gs6   =utility.add_gridspec_abs(fig, nrows=1, ncols=1,\n",
    "                                    top=gs5.top*figsize[1],\n",
    "                                    right=figsize[0],\n",
    "                                    width=params.panels.decoding_hist[0],\n",
    "                                    height=params.panels.decoding_hist[1])\n",
    "\n",
    "    ax6 = fig.add_subplot(gs6[0])\n",
    "\n",
    "       \n",
    "    plot_monkey_decoding(ax6, allDFs_MCx, redo=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    # 7: schematics Mouse\n",
    "    gs7   =utility.add_gridspec_abs(fig, nrows=1, ncols=1, left=0, \n",
    "                                    bottom=gs6.bottom*figsize[1]-params.panels.schmatic[1],\n",
    "                                    width=params.panels.schmatic[0],\n",
    "                                    height=params.panels.cca[1])\n",
    "    ax7   =fig.add_subplot(gs7[0])\n",
    "    ax7 = utility.phantom_axes(ax7)\n",
    "    ax7.set_facecolor([0,1,0,0])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    # 8: CCA plot for MICE\n",
    "    gs8 = fig.add_gridspec(nrows=1, ncols=2,  width_ratios=(params.panels.cca[0],params.panels.cca_hist[0]-params.panels.cca[0]),\n",
    "                           left=gs5.left,\n",
    "                           right=gs5.right,\n",
    "                           bottom=gs7.bottom,\n",
    "                           top=gs7.top,\n",
    "                           wspace=0)\n",
    "\n",
    "    ax8 = fig.add_subplot(gs8[0])\n",
    "    ax8_ = fig.add_subplot(gs8[1])\n",
    "    \n",
    "    \n",
    "    allDFs_M1, _ = get_full_mouse_data()\n",
    "    \n",
    "    plot_mouse_cca(ax8,ax8_, allDFs_M1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    # 9: Behaviour vs CCA\n",
    "    gs9   =utility.add_gridspec_abs(fig, nrows=1, ncols=1,\n",
    "                                    top=gs7.top*figsize[1],\n",
    "                                    right=figsize[0],\n",
    "                                    width=params.panels.neuro_behav_corr[0],\n",
    "                                    height=params.panels.neuro_behav_corr[1])\n",
    "    gs9_inset   =utility.add_gridspec_abs(fig, nrows=1, ncols=1,\n",
    "                                                left=gs9.right*figsize[0]-.7,\n",
    "                                                bottom=gs9.bottom*figsize[1]+.1,\n",
    "                                                width=.7,\n",
    "                                                height=params.panels.TinyH)\n",
    "    ax9 = fig.add_subplot(gs9[0])\n",
    "    ax9_ = fig.add_subplot(gs9_inset[0])\n",
    "\n",
    "\n",
    "    \n",
    "    mouse_behav, mouse_cc = plot_mouse_cca_corr(ax9, allDFs_M1)\n",
    "    monkey_behav, monkey_cc = plot_monkey_cca_corr(ax9, allDFs_MCx)\n",
    "\n",
    "    m, b, r_val, p_val, _ = linregress(mouse_behav, mouse_cc) \n",
    "    print('mouse only\"', r_val, p_val)\n",
    "    m, b, r_val, p_val, _ = linregress(monkey_behav, monkey_cc)\n",
    "    print('monkey only\"', r_val, p_val)\n",
    "    m, b, r_val, p_val, _ = linregress(np.concatenate([mouse_behav, monkey_behav]), np.concatenate([mouse_cc, monkey_cc]))\n",
    "    print('monkey and mouse\"', r_val, p_val)\n",
    "\n",
    "    plot_traj_corr(ax9_, allDFs_MCx, allDFs_M1)\n",
    "\n",
    "    \n",
    "#     fig.align_ylabels([ax1,ax4])\n",
    "    #############################################\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    AXES=(ax1,axes2_1[0],axes3[0],ax4,ax5,ax6,ax7,ax8,ax9)\n",
    "    OFFX=np.array([.02]*len(AXES))\n",
    "    OFFY=np.array([.01]*len(AXES))\n",
    "    # OFFX[[-1]]=0.12\n",
    "    OFFX[[0,2,3,4,5,6,7,8]]=0.05\n",
    "    \n",
    "    params.add_panel_caption(axes=AXES, offsetX=OFFX, offsetY=OFFY)\n",
    "    \n",
    "    fig.savefig(FIGPATH / 'figure2.pdf', format='pdf', bbox_inches='tight')\n",
    "    \n",
    "\n",
    "    ##########################################\n",
    "    # monkey schematics\n",
    " \n",
    "    thisPath  =str(FIGPATH / 'figure2.pdf')\n",
    "    sketchPath=str(params.figPath / 'monkey-task-schematic.pdf')\n",
    "    if os.path.exists(sketchPath):\n",
    "        f1=ppdf.PdfFileReader(thisPath).getPage(0)\n",
    "        f2=ppdf.PdfFileReader(sketchPath).getPage(0)\n",
    "\n",
    "        f1.mergeTranslatedPage(page2=f2, tx=10, ty=347, expand=False)\n",
    "\n",
    "        writer=ppdf.PdfFileWriter()\n",
    "        writer.addPage(f1)\n",
    "        with open(thisPath,'wb') as f3:\n",
    "            writer.write(f3)\n",
    "\n",
    "\n",
    "\n",
    "    ##########################################\n",
    "    # mouse schematics\n",
    "            \n",
    "    thisPath  =str(FIGPATH / 'figure2.pdf')\n",
    "    sketchPath=str(params.figPath / 'mouse-task-schematic.pdf')\n",
    "    if os.path.exists(sketchPath):\n",
    "        f1=ppdf.PdfFileReader(thisPath).getPage(0)\n",
    "        f2=ppdf.PdfFileReader(sketchPath).getPage(0)\n",
    "\n",
    "        f1.mergeTranslatedPage(page2=f2, tx=10, ty=20, expand=False)\n",
    "\n",
    "        writer=ppdf.PdfFileWriter()\n",
    "        writer.addPage(f1)\n",
    "        with open(thisPath,'wb') as f3:\n",
    "            writer.write(f3)\n",
    "clear_output()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f438ab41c639bccf4a0690d593feedbc6f327eadb4a78567565a57c35fedcdae"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('cca': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "146bff742f048d001dec7fafb91c8daeb769f9aeaad9c8d129a83c9f9fb9a9b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
