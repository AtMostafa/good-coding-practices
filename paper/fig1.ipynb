{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b102c0",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00059128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "from pprint import pprint\n",
    "import gc\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging, warnings\n",
    "# logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.collections import LineCollection\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pyaldata as pyal\n",
    "\n",
    "try:\n",
    "    nbPath = pathlib.Path.cwd()\n",
    "    RepoPath = nbPath.parent\n",
    "    os.chdir(RepoPath)\n",
    "\n",
    "    from tools import utilityTools as utility\n",
    "    from tools import dataTools as dt\n",
    "    import params\n",
    "    monkey_defs = params.monkey_defs\n",
    "    mouse_defs = params.mouse_defs\n",
    "\n",
    "    set_rc =  params.set_rc_params\n",
    "    set_rc()\n",
    "    root = params.root\n",
    "    \n",
    "    os.chdir(RepoPath / 'monkey')\n",
    "    %run \"_dataset-selection.ipynb\"\n",
    "\n",
    "finally:\n",
    "    os.chdir(nbPath)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda7bed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Load the lower bound values for the canonical correlations\n",
    "\n",
    "takes a couple of minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"_lower-bound.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778b4e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "#### Load the upper bound values for the canonical correlations\n",
    "\n",
    "takes a couple of minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"_upper-bound.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd70236",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "back to the original idea:\n",
    "\n",
    "1. this:\n",
    "> # Compare different epochs\n",
    "> the idea is to see whether canonical axes between 2 animals provide a higher VAF for time epochs in the trial that they have not been trained on, compared to, for example, M1-PMd axes in a single animal.\n",
    "\n",
    "2. and a similar but different idea:\n",
    "> two monkeys during the same epoch vs. one monkey between 2 different epochs.\n",
    "i.e., preparation vs execution, ...\n",
    "\n",
    "#### Try the second idea first:\n",
    "\n",
    "# CCA comparison\n",
    "\n",
    "## 2 monkeys, same epoch\n",
    "\n",
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d23e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list_MCx = []\n",
    "for animal, sessionList in GoodDataList[defs.areas[2]].items():\n",
    "    if 'Mr' in animal:\n",
    "        continue  # to remove MrT\n",
    "    full_list_MCx.append((animal,sessionList))\n",
    "full_list_MCx = [(animal,session) for animal,sessions in full_list_MCx for session in set(sessions)]\n",
    "# load the DFs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "allDFs_MCx = []\n",
    "for animal, session in full_list_MCx:\n",
    "    path = root/animal/session\n",
    "    allDFs_MCx.append(defs.prep_general(dt.load_pyal_data(path)))\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "\n",
    "pairFileList1 = []\n",
    "for I, (animal1,session1) in enumerate(full_list_MCx):\n",
    "    for J, (animal2,session2) in enumerate(full_list_MCx):\n",
    "        if J<=I or animal1 == animal2: continue  # to repetitions\n",
    "        if 'Chewie' in animal1 and 'Chewie' in animal2: continue \n",
    "        pairFileList1.append((I,J))\n",
    "\n",
    "print(f'{len(pairFileList1)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7ff66",
   "metadata": {},
   "source": [
    "collecting all the data in a matrix, `AllData`: $sessions \\times targets \\times  trials \\times time \\times PCs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "side1df = [allDFs_MCx[i] for i,_ in pairFileList1]\n",
    "side2df = [allDFs_MCx[j] for _,j in pairFileList1]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "AllData1 = dt.get_data_array(side1df, defs.exec_epoch, area=defs.areas[2], model=defs.n_components)\n",
    "AllData2 = dt.get_data_array(side2df, defs.exec_epoch, area=defs.areas[2], model=defs.n_components)\n",
    "_,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "print(f'{min_trials=}\\n{min_time=}')\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "allCCs0=[]\n",
    "for sessionData1,sessionData2 in zip(AllData1,AllData2):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "    allCCs0.append(dt.canoncorr(data1, data2))\n",
    "allCCs0 = np.array(allCCs0).T\n",
    "\n",
    "# plot\n",
    "_,ax = plt.subplots(dpi=100)\n",
    "utility.shaded_errorbar(ax, allCCs0, color='b', marker = 'o', label=f'{defs.areas[2]} $n={allCCs0.shape[1]}$ sessions')\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('components')\n",
    "ax.legend()\n",
    "ax.set_ylabel('canonical correlation')\n",
    "ax.set_title('CCA --- across monkey', usetex=True);\n",
    "\n",
    "_,ax = plt.subplots(ncols=1, figsize=(10,5))\n",
    "ax.plot(allCCs0[:4,:].mean(axis=0),'.')\n",
    "ax.set_ylabel('average canonical correlation')\n",
    "ax.set_title(f'CCA --- across monkey {defs.areas[2]} ', usetex=True);\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('sessions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd10ae3e",
   "metadata": {},
   "source": [
    "### Overall Figures\n",
    "\n",
    "across monkey and within monkey together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920865dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig,ax = plt.subplots(ncols=1, figsize=(3,3))\n",
    "\n",
    "utility.shaded_errorbar(ax, np.arange(1,defs.n_components+1), allCCs0, color='b', marker = 'o', label=f'Across, $n={allCCs0.shape[1]}$')\n",
    "\n",
    "utility.shaded_errorbar(ax, np.arange(1,defs.n_components+1), CC_upper_bound_MCx, color='cornflowerblue', marker = '<', ls='--', label=f'Within, $n={CC_upper_bound_MCx.shape[1]}$')\n",
    "\n",
    "utility.shaded_errorbar(ax, np.arange(1,defs.n_components+1), CC_lower_bound_MCx, color='gray', marker = '>', ls=':', label=f'Control, $n={CC_lower_bound_MCx.shape[1]}$')\n",
    "\n",
    "\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlim([.5,defs.n_components+.5])\n",
    "ax.set_xlabel('Neural mode')\n",
    "ax.set_title(f'{defs.areas[2]} Alignment')\n",
    "ax.legend(loc=(.35,.7))\n",
    "ax.set_ylabel('Canonical correlation')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(params.figPath / 'monkey-cca-modes.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82581e9d",
   "metadata": {},
   "source": [
    "comapring group correlations\n",
    ">Like the NN paper, _Fig. 4e_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=1, figsize=(3,3))\n",
    "bins = np.arange(0,1,0.05)\n",
    "\n",
    "ax.hist(allCCs0[:4,:].mean(axis=0), bins=bins, density=True,\n",
    "        color='b', alpha=.8, label=f'across, $n={allCCs0[:4,:].mean(axis=0).shape[0]}$')\n",
    "ax.hist(CC_upper_bound_MCx[:4,:].mean(axis=0), bins=bins, density=True,\n",
    "        color='cornflowerblue', alpha=.8, label=f'within, $n={CC_upper_bound_MCx[:4,:].mean(axis=0).shape[0]}$')\n",
    "ax.hist(CC_lower_bound_MCx[:4,:].mean(axis=0), bins=bins, density=True,\n",
    "        color='gray', alpha=.8, label=f'control, $n={CC_lower_bound_MCx[:4,:].mean(axis=0).shape[0]}$')\n",
    "\n",
    "ax.set_title(f'Average of top 4 CCs in {defs.areas[2]}')\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_xlabel('Canonical correlation')\n",
    "ax.set_ylabel('Probability')\n",
    "# ax.set_yticks([])\n",
    "ax.legend(loc=2)\n",
    "\n",
    "fig.savefig(params.figPath / 'monkey-cca-dist.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c10b4-e1e8-4616-ab6c-066996205e1e",
   "metadata": {},
   "source": [
    "# For Preparation epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a733778-2ad5-4108-9c24-99a332de0f86",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "#### Load the upper bound values for the canonical correlations\n",
    "\n",
    "takes a couple of minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8a37b-596a-4884-856d-ee8e3fcfc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"_upper-bound-prep.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10216802-200e-467a-a9ea-0eeb19ccc6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "side1df = [allDFs_MCx[i] for i,_ in pairFileList1]\n",
    "side2df = [allDFs_MCx[j] for _,j in pairFileList1]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "AllData1 = dt.get_data_array(side1df, defs.prep_epoch, area=defs.areas[2], model=defs.n_components)\n",
    "AllData2 = dt.get_data_array(side2df, defs.prep_epoch, area=defs.areas[2], model=defs.n_components)\n",
    "_,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "print(f'{min_trials=}\\n{min_time=}')\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "allCCs1=[]\n",
    "for sessionData1,sessionData2 in zip(AllData1,AllData2):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,defs.n_components))\n",
    "    allCCs1.append(dt.canoncorr(data1, data2))\n",
    "allCCs1 = np.array(allCCs1).T\n",
    "\n",
    "# plot\n",
    "\n",
    "_,ax = plt.subplots(dpi=100)\n",
    "utility.shaded_errorbar(ax, allCCs1, color='b', marker = 'o', label=f'{defs.areas[2]} $n={allCCs1.shape[1]}$ sessions')\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('components')\n",
    "ax.legend()\n",
    "ax.set_ylabel('canonical correlation')\n",
    "ax.set_title('CCA --- across monkey')\n",
    "\n",
    "_,ax = plt.subplots(ncols=1, figsize=(10,5), dpi=100)\n",
    "ax.plot(allCCs1[:4,:].mean(axis=0),'.')\n",
    "ax.set_ylabel('average canonical correlation')\n",
    "ax.set_title(f'CCA --- across monkey {defs.areas[2]}');\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('sessions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fb2ad-98ea-43db-847f-6cf3c77a3075",
   "metadata": {},
   "source": [
    "# Overall PREP epoch Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2eab68-04ab-4c44-b415-85316c976158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig,ax = plt.subplots(ncols=1, figsize=(3,3))\n",
    "\n",
    "utility.shaded_errorbar(ax, np.arange(1,defs.n_components+1), allCCs1, color='b', marker = 'o', label=f'Across, $n={allCCs1.shape[1]}$')\n",
    "\n",
    "utility.shaded_errorbar(ax, np.arange(1,defs.n_components+1), CC_upper_bound_MCx, color='cornflowerblue', marker = '<', ls='--', label=f'Within, $n={CC_upper_bound_MCx.shape[1]}$')\n",
    "\n",
    "utility.shaded_errorbar(ax, np.arange(1,defs.n_components+1), CC_lower_bound_MCx, color='gray', marker = '>', ls=':', label=f'Control, $n={CC_lower_bound_MCx.shape[1]}$')\n",
    "\n",
    "\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlim([.5,defs.n_components+.5])\n",
    "ax.set_xlabel('Neural mode')\n",
    "ax.set_title(f'{defs.areas[2]} preparation alignment')\n",
    "ax.legend(loc=(.35,.7))\n",
    "ax.set_ylabel('Canonical correlation')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(params.figPath / 'monkey-prep-cca-modes.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f4b46-19a6-47e7-8a6f-0af7be4d5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=1, figsize=(3,3))\n",
    "bins = np.arange(0,1,0.05)\n",
    "\n",
    "ax.hist(allCCs1[:4,:].mean(axis=0), bins=bins, density=True,\n",
    "        color='b', alpha=.8, label=f'Across, $n={allCCs1[:4,:].mean(axis=0).shape[0]}$')\n",
    "ax.hist(CC_upper_bound_MCx[:4,:].mean(axis=0), bins=bins, density=True,\n",
    "        color='cornflowerblue', alpha=.8, label=f'Within, $n={CC_upper_bound_MCx[:4,:].mean(axis=0).shape[0]}$')\n",
    "ax.hist(CC_lower_bound_MCx[:4,:].mean(axis=0), bins=bins, density=True,\n",
    "        color='gray', alpha=.8, label=f'Control, $n={CC_lower_bound_MCx[:4,:].mean(axis=0).shape[0]}$')\n",
    "\n",
    "ax.set_title(f'Top 4 CCs during prep. --- {defs.areas[2]}')\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_xlabel('Canonical correlation')\n",
    "ax.set_ylabel('Probability')\n",
    "# ax.set_yticks([])\n",
    "ax.legend(loc=2)\n",
    "\n",
    "fig.savefig(params.figPath / 'monkey-prep-cca-dist.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a7186",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## one monkey, 2 epochs\n",
    "\n",
    "as an extra control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_FileList1 = []\n",
    "for I, _ in enumerate(full_list_M1):\n",
    "    single_FileList1.append(I)\n",
    "\n",
    "print(f'{len(single_FileList1)=}')\n",
    "\n",
    "single_FileList2 = []\n",
    "for I, (animal1,session1) in enumerate(full_list_PMd):\n",
    "    single_FileList2.append(I)\n",
    "\n",
    "print(f'{len(single_FileList2)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c75f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "side1df = [allDFs_M1[i] for i in single_FileList1]\n",
    "\n",
    "AllData1 = dt.get_data_array(side1df, prep_epoch, area=areas[0], model=n_components)\n",
    "AllData2 = dt.get_data_array(side1df, exec_epoch, area=areas[0], model=n_components)\n",
    "_,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "print(f'{min_trials=}\\n{min_time=}')\n",
    "\n",
    "# PMd\n",
    "side2df = [allDFs_PMd[j] for j in single_FileList2]\n",
    "\n",
    "AllData1_ = dt.get_data_array(side2df, prep_epoch, area=areas[1], model=n_components)\n",
    "AllData2_ = dt.get_data_array(side2df, exec_epoch, area=areas[1], model=n_components)\n",
    "_,_, min_trials_, min_time_,_ = np.min((AllData1_.shape,AllData2_.shape),axis=0)\n",
    "print(f'{min_trials_=}\\n{min_time_=}')\n",
    "\n",
    "inCCs0=[]\n",
    "for sessionData1,sessionData2 in zip(AllData1,AllData2):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,n_components))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,n_components))\n",
    "    inCCs0.append(dt.canoncorr(data1, data2))\n",
    "inCCs0 = np.array(inCCs0).T\n",
    "\n",
    "inCCs1=[]\n",
    "for sessionData1,sessionData2 in zip(AllData1_,AllData2_):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials_,:min_time_,:], (-1,n_components))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials_,:min_time_,:], (-1,n_components))\n",
    "    inCCs1.append(dt.canoncorr(data1, data2))\n",
    "inCCs1 = np.array(inCCs1).T\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# plotting\n",
    "_,ax = plt.subplots()\n",
    "\n",
    "utility.shaded_errorbar(ax, inCCs0, color='b', marker = 'o', label=f'{areas[0]} $n={inCCs0.shape[1]}$ sessions')\n",
    "utility.shaded_errorbar(ax, inCCs1, color='r', marker = 'o', label=f'{areas[1]} $n={inCCs1.shape[1]}$ sessions')\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('components')\n",
    "ax.legend()\n",
    "ax.set_ylabel('canonical correlation')\n",
    "ax.set_title('CCA --- within monkey', usetex=True);\n",
    "\n",
    "fig,axes = plt.subplots(ncols=2, figsize=(10,5))\n",
    "axes[0].plot(inCCs0[:4,:].mean(axis=0),'.')\n",
    "axes[1].plot(inCCs1[:4,:].mean(axis=0),'.')\n",
    "axes[0].set_ylabel('average canonical correlation')\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_title(f'CCA --- within monkey {areas[i]} ', usetex=True);\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_xlabel('sessions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ceb34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## one monkey, 2 areas\n",
    "\n",
    "as an extra control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list_dual = []\n",
    "for animal, sessionList in GoodDataList[areas[0]].items():\n",
    "    if 'Mr' in animal:\n",
    "        continue  # to remove MrT\n",
    "    full_list_M1.append((animal,sessionList))\n",
    "full_list_M1 = [(animal,session) for animal,sessions in full_list_M1 for session in set(sessions)]\n",
    "# load the DFs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "allDFs_M1 = []\n",
    "for animal, session in full_list_M1:\n",
    "    path = root/animal/session\n",
    "    allDFs_M1.append(prep_general(dt.load_pyal_data(path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504d1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d0a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95683c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db0935bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# VAF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365eb43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_data_and_pca(data_list: list[pd.DataFrame], epoch , area: str ='M1', n_components: int =10) -> tuple[np.ndarray, sklearn.decomposition._pca.PCA]:\n",
    "    \"\"\"\n",
    "    Applies PCA to the data and return a data matrix of the shape: sessions x targets x  trials x time x PCs\n",
    "    with the minimum number of trials and timepoints shared across all the datasets/targets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    `data_list`: list of pd.dataFrame datasets from pyal-data\n",
    "    `epoch`: an epoch function of the type `pyal.generate_epoch_fun`\n",
    "    `area`: area, either: 'M1', or 'S1', or 'PMd'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `AllData`: np.array\n",
    "    `AllPCA`: list of pca objects of each session\n",
    "\n",
    "    Signature\n",
    "    -------\n",
    "    AllData = get_data_array(data_list, execution_epoch, area='M1', n_components=10)\n",
    "    all_data = np.reshape(AllData, (-1,10))\n",
    "    \"\"\"\n",
    "    field = f'{area}_rates'\n",
    "    n_shared_trial = np.inf\n",
    "    n_unit = np.inf\n",
    "    for df in data_list:\n",
    "        n_unit = np.min((df[field][0].shape[1], n_unit))\n",
    "        for target in range(8):\n",
    "            df_ = pyal.select_trials(df, df.target_id== target)\n",
    "            n_shared_trial = np.min((df_.shape[0], n_shared_trial))\n",
    "\n",
    "    n_shared_trial = int(n_shared_trial)\n",
    "    n_unit = int(n_unit)\n",
    "\n",
    "    # finding the number of timepoints\n",
    "    df_ = pyal.restrict_to_interval(df_,epoch_fun=epoch)\n",
    "    n_timepoints = int(df_[field][0].shape[0])\n",
    "\n",
    "    # pre-allocating the data matrix\n",
    "    AllData = np.empty((len(data_list), 8, n_shared_trial, n_timepoints, n_unit))\n",
    "    AllPCA = []\n",
    "    rng = np.random.default_rng(12345)\n",
    "    for session, df in enumerate(data_list):\n",
    "        df_ = pyal.restrict_to_interval(df, epoch_fun=epoch)\n",
    "        rates = np.concatenate(df_[field].values, axis=0)\n",
    "        rates -= np.mean(rates, axis=0)\n",
    "        all_units = np.arange(rates.shape[1])\n",
    "        rng.shuffle(all_units)\n",
    "        rates_model = PCA(n_components=n_components, svd_solver='full').fit(rates[:,all_units[:n_unit]])\n",
    "        AllPCA.append(rates_model)\n",
    "        \n",
    "        for target in range(8):\n",
    "            df__ = pyal.select_trials(df_, df_.target_id==target)\n",
    "            all_id = df__.trial_id.to_numpy()\n",
    "            rng.shuffle(all_id)\n",
    "            # select the right number of trials to each target\n",
    "            df__ = pyal.select_trials(df__, lambda trial: trial.trial_id in all_id[:n_shared_trial])\n",
    "            for trial, trial_rates in enumerate(df__[field]):\n",
    "                AllData[session,target,trial, :, :] = trial_rates [:,all_units[:n_unit]]\n",
    "    \n",
    "    return AllData, AllPCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c45e5",
   "metadata": {},
   "source": [
    "## 2 monkeys, same epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c876c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pairFileList1 = []\n",
    "for I, animal1 in enumerate(GoodDataList[areas[0]]):\n",
    "    for J, animal2 in enumerate(GoodDataList[areas[0]]):\n",
    "        if J<=I or '2' in animal1+animal2:  # to repetitions and to remove Chewie2\n",
    "            continue\n",
    "        path1List = [root/animal1/GoodDataList[areas[0]][animal1][i] for i,_ in enumerate(GoodDataList[areas[0]][animal1])]\n",
    "        path2List = [root/animal2/GoodDataList[areas[0]][animal2][i] for i,_ in enumerate(GoodDataList[areas[0]][animal2])]\n",
    "        for path1 in path1List:\n",
    "            df1 = dt.load_pyal_data(path1)\n",
    "            for path2 in path2List:\n",
    "                pairFileList1.append((df1, dt.load_pyal_data(path2)))\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "pairFileList_area0 = [(prep_general(df1),prep_general(df2)) for  df1,df2 in pairFileList1]\n",
    "del pairFileList1\n",
    "gc.collect()\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "side1df = [df for df,_ in pairFileList_area0]\n",
    "side2df = [df for _,df in pairFileList_area0]\n",
    "AllData1, AllPca1 = get_unit_data_and_pca(side1df, exec_epoch, area=areas[0], n_components=n_components)\n",
    "AllData2, AllPca2 = get_unit_data_and_pca(side2df, exec_epoch, area=areas[0], n_components=n_components)\n",
    "_,_, min_trials, min_time, _ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "\n",
    "\n",
    "allVAFs=[]\n",
    "for sessionData1,sessionData2, model1, model2 in zip(AllData1, AllData2, AllPca1, AllPca2):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,sessionData1.shape[-1]))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,sessionData2.shape[-1]))\n",
    "    A, B, *_ = dt.canoncorr(model1.transform(data1), model2.transform(data2), fullReturn=True)\n",
    "    allVAFs.append(dt.VAF_pc_cc(X=data1, C=model1.components_, A=A)+dt.VAF_pc_cc(X=data2, C=model2.components_, A=B))\n",
    "allVAFs = np.cumsum(np.array(allVAFs).T /2, axis=0)\n",
    "\n",
    "\n",
    "# plot\n",
    "_,ax = plt.subplots()\n",
    "utility.shaded_errorbar(ax, allVAFs, color='b', marker = 'o', label=f'{areas[0]} $n={allVAFs.shape[1]}$ sessions')\n",
    "ax.plot(allVAFs,lw=1, alpha=.3);\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('axes')\n",
    "ax.legend()\n",
    "ax.set_ylabel('VAF')\n",
    "ax.set_title('VAF --- M1 across monkeys', usetex=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pairFileList2 = []\n",
    "for I, animal1 in enumerate(GoodDataList[areas[1]]):\n",
    "    for J, animal2 in enumerate(GoodDataList[areas[1]]):\n",
    "        if J<=I or '2' in animal1+animal2:  # to repetitions and to remove Chewie2\n",
    "            continue\n",
    "        path1List = [root/animal1/GoodDataList[areas[1]][animal1][i] for i,_ in enumerate(GoodDataList[areas[1]][animal1])]\n",
    "        path2List = [root/animal2/GoodDataList[areas[1]][animal2][i] for i,_ in enumerate(GoodDataList[areas[1]][animal2])]\n",
    "        for path1 in path1List:\n",
    "            df1 = dt.load_pyal_data(path1)\n",
    "            for path2 in path2List:\n",
    "                pairFileList2.append((df1, dt.load_pyal_data(path2)))\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "pairFileList_area1 = [(prep_general(df1),prep_general(df2)) for  df1,df2 in pairFileList2]\n",
    "del pairFileList2\n",
    "gc.collect()\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "side1df = [df for df,_ in pairFileList_area1]\n",
    "side2df = [df for _,df in pairFileList_area1]\n",
    "AllData1, AllPca1 = get_unit_data_and_pca(side1df, exec_epoch, area=areas[1], n_components=n_components)\n",
    "AllData2, AllPca2 = get_unit_data_and_pca(side2df, exec_epoch, area=areas[1], n_components=n_components)\n",
    "_,_, min_trials, min_time, _ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "\n",
    "\n",
    "allVAFs2=[]\n",
    "for sessionData1,sessionData2, model1, model2 in zip(AllData1, AllData2, AllPca1, AllPca2):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,sessionData1.shape[-1]))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,sessionData2.shape[-1]))\n",
    "    A, B, *_ = dt.canoncorr(model1.transform(data1), model2.transform(data2), fullReturn=True)\n",
    "    allVAFs2.append(dt.VAF_pc_cc(X=data1, C=model1.components_, A=A)+dt.VAF_pc_cc(X=data2, C=model2.components_, A=B))\n",
    "allVAFs2 = np.cumsum(np.array(allVAFs2).T / 2, axis=0)\n",
    "\n",
    "\n",
    "# plot\n",
    "_,ax = plt.subplots()\n",
    "utility.shaded_errorbar(ax, allVAFs2, color='b', marker = 'o', label=f'{areas[1]} $n={allVAFs.shape[1]}$ sessions')\n",
    "ax.plot(allVAFs2,lw=1, alpha=.3);\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('axes')\n",
    "ax.legend()\n",
    "ax.set_ylabel('VAF')\n",
    "ax.set_title('VAF --- PMd across monkeys', usetex=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968dcaf",
   "metadata": {},
   "source": [
    "## one monkey, two epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairFileList1 = []\n",
    "for animal1 in GoodDataList[areas[0]]:\n",
    "    path1List = [root/animal1/GoodDataList[areas[0]][animal1][i] for i,_ in enumerate(GoodDataList[areas[0]][animal1])]\n",
    "    for path1 in path1List:\n",
    "        df1 = dt.load_pyal_data(path1)\n",
    "        pairFileList1.append(df1)\n",
    "\n",
    "print(f'{len(pairFileList1)=}')\n",
    "\n",
    "pairFileList2 = []\n",
    "for animal1 in GoodDataList[areas[1]]:\n",
    "    path1List = [root/animal1/GoodDataList[areas[1]][animal1][i] for i,_ in enumerate(GoodDataList[areas[1]][animal1])]\n",
    "    for path1 in path1List:\n",
    "        df1 = dt.load_pyal_data(path1)\n",
    "        pairFileList2.append(df1)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "gc.collect()\n",
    "pairFileList_area0 = [prep_general(df) for df in pairFileList1]\n",
    "del pairFileList1\n",
    "gc.collect()\n",
    "pairFileList_area1 = [prep_general(df) for  df in pairFileList2]\n",
    "del pairFileList2\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "side1df = pairFileList_area0\n",
    "AllData1, AllPca1 = get_unit_data_and_pca(side1df, prep_epoch, area=areas[0], n_components=n_components)\n",
    "AllData2, AllPca2 = get_unit_data_and_pca(side1df, exec_epoch, area=areas[0], n_components=n_components)\n",
    "_,_, min_trials, min_time,_ = np.min((AllData1.shape,AllData2.shape),axis=0)\n",
    "print(f'{min_trials=}\\n{min_time=}')\n",
    "# PMd\n",
    "side2df = pairFileList_area1\n",
    "AllData1_, AllPca1_ = get_unit_data_and_pca(side2df, prep_epoch, area=areas[1], n_components=n_components)\n",
    "AllData2_, AllPca2_ = get_unit_data_and_pca(side2df, exec_epoch, area=areas[1], n_components=n_components)\n",
    "_,_, min_trials_, min_time_,_ = np.min((AllData1_.shape,AllData2_.shape),axis=0)\n",
    "print(f'{min_trials_=}\\n{min_time_=}')\n",
    "\n",
    "inVAFs0=[]\n",
    "for sessionData1,sessionData2,model1,model2 in zip(AllData1,AllData2,AllPca1,AllPca2):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,sessionData1.shape[-1]))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,sessionData2.shape[-1]))\n",
    "    A, B, *_ = dt.canoncorr(model1.transform(data1), model2.transform(data2), fullReturn=True)\n",
    "    inVAFs0.append(dt.VAF_pc_cc(X=data1, C=model1.components_, A=A)+dt.VAF_pc_cc(X=data2, C=model2.components_, A=B))\n",
    "inVAFs0 = np.cumsum(np.array(inVAFs0).T / 2, axis=0)\n",
    "\n",
    "inVAFs1=[]\n",
    "for sessionData1,sessionData2,model1,model2 in zip(AllData1_,AllData2_,AllPca1_,AllPca2_):\n",
    "    data1 = np.reshape(sessionData1[:,:min_trials,:min_time,:], (-1,sessionData1.shape[-1]))\n",
    "    data2 = np.reshape(sessionData2[:,:min_trials,:min_time,:], (-1,sessionData2.shape[-1]))\n",
    "    A, B, *_ = dt.canoncorr(model1.transform(data1), model2.transform(data2), fullReturn=True)\n",
    "    inVAFs1.append(dt.VAF_pc_cc(X=data1, C=model1.components_, A=A)+dt.VAF_pc_cc(X=data2, C=model2.components_, A=B))\n",
    "inVAFs1 = np.cumsum(np.array(inVAFs1).T / 2, axis=0)\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "\n",
    "# plotting\n",
    "_,ax = plt.subplots()\n",
    "\n",
    "utility.shaded_errorbar(ax, inVAFs0, color='b', marker = 'o', label=f'{areas[0]} $n={inVAFs0.shape[1]}$ sessions')\n",
    "utility.shaded_errorbar(ax, inVAFs1, color='r', marker = 'o', label=f'{areas[1]} $n={inVAFs1.shape[1]}$ sessions')\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('axes')\n",
    "ax.legend()\n",
    "ax.set_ylabel('VAF')\n",
    "ax.set_title('VAF --- within monkeys', usetex=True);\n",
    "\n",
    "fig,axes = plt.subplots(ncols=2, figsize=(10,5))\n",
    "utility.shaded_errorbar(axes[0], allVAFs, color='b', marker = 'o', label=f'Across monkeys $n={allVAFs.shape[1]}$ sessions')\n",
    "utility.shaded_errorbar(axes[0], inVAFs0, color='r', marker = 'o', label=f'Within monkeys $n={inVAFs0.shape[1]}$ sessions')\n",
    "utility.shaded_errorbar(axes[1], allVAFs2, color='b', marker = 'o', label=f'Across monkeys $n={allVAFs2.shape[1]}$ sessions')\n",
    "utility.shaded_errorbar(axes[1], inVAFs1,  color='r', marker = 'o', label=f'Within monkeys $n={inVAFs1.shape[1]}$ sessions')\n",
    "\n",
    "axes[0].set_ylabel('average VAF')\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_title(f'VAF --- {areas[i]} ', usetex=True);\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_xlabel('CC axes')\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72da6499f934495e06c03d484049d4696c0f7b78c6b9c64cf8676e9ec2014a6a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
