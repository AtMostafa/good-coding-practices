{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06debf48",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f206a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os, sys, pathlib\n",
    "from pprint import pprint\n",
    "import gc\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging, warnings\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer, r2_score, explained_variance_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyaldata as pyal\n",
    "\n",
    "try:\n",
    "    nbPath = pathlib.Path.cwd()\n",
    "    RepoPath = nbPath.parent\n",
    "    os.chdir(RepoPath)\n",
    "\n",
    "    from tools import utilityTools as utility\n",
    "    from tools import dataTools as dt\n",
    "    from tools import lstm\n",
    "    import params\n",
    "    defs = params.monkey_defs\n",
    "    monkey_defs = defs\n",
    "    \n",
    "    set_rc =  params.set_rc_params\n",
    "    set_rc()\n",
    "    root = params.root\n",
    "    reload(params)\n",
    "    reload(defs)\n",
    "\n",
    "finally:\n",
    "    os.chdir(nbPath)\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "\n",
    "    %run \"_dataset-selection.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd20b87-b313-4b4f-96bf-46dfab428c62",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6aca7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_list = []\n",
    "for animal, sessionList in GoodDataList[defs.areas[2]].items():\n",
    "    if 'Mr' in animal:\n",
    "        continue  # to remove MrT\n",
    "    full_list.append((animal,sessionList))\n",
    "full_list = [(animal,session) for animal,sessions in full_list for session in set(sessions)]\n",
    "\n",
    "# load the DFs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "allDFs = []\n",
    "for animal, session in full_list:\n",
    "    path = root/animal/session\n",
    "    allDFs.append(defs.prep_general(dt.load_pyal_data(path)))\n",
    "warnings.filterwarnings(\"default\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56ee1125",
   "metadata": {},
   "source": [
    "## Plotting decoding performance using VAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d12a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_r2_vaf(y_true, y_pred):\n",
    "    mask = np.logical_and(np.logical_not(np.isnan(y_true)),\n",
    "                          np.logical_not(np.isnan(y_pred)))\n",
    "    return explained_variance_score(y_true[mask], y_pred[mask])\n",
    "\n",
    "\n",
    "def custom_r2_corr(y_true, y_pred):\n",
    "    \"$R^2$ value as squared correlation coefficient, as per Gallego, NN 2020\"\n",
    "\n",
    "    mask = np.logical_and(np.logical_not(np.isnan(y_true)),\n",
    "                          np.logical_not(np.isnan(y_pred)))\n",
    "    c = np.corrcoef(y_true[mask].T, y_pred[mask].T) ** 2\n",
    "    return np.diag(c[-int(c.shape[0]/2):,:int(c.shape[1]/2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3c0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monkey_decoding(ax, allDFs, custom_r2_func):\n",
    "    defs = monkey_defs\n",
    "\n",
    "    within_score = {}\n",
    "    aligned_score = {}\n",
    "    unaligned_score = {}\n",
    "    for i, df1 in enumerate(tqdm(allDFs)):\n",
    "        AllData, AllVel = defs.get_data_array_and_vel([df1], defs.exec_epoch_decode,\n",
    "                                                    area=defs.areas[2], n_components=defs.n_components)\n",
    "        # adding history\n",
    "        AllData = dt.add_history_to_data_array(AllData,defs.MAX_HISTORY)\n",
    "        AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "        AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "        AllData1 = AllData[0,...]\n",
    "        AllVel1 = AllVel[0,...]\n",
    "        *_,n_time,n_comp = AllData1.shape\n",
    "        # resizing\n",
    "        X1 = AllData1.reshape((-1,n_time,n_comp))\n",
    "        AllVel1 = AllVel1.reshape((-1,n_time,2))\n",
    "        \n",
    "        fold_score =[]\n",
    "        kf = KFold(n_splits=10)\n",
    "        for train_index, test_index in kf.split(X1[:,0,0]):\n",
    "            x_train, x_test = X1[train_index,...], X1[test_index,...]\n",
    "            y_train, y_test = AllVel1[train_index,...], AllVel1[test_index,...]\n",
    "\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=X1.shape[-1], output_dims=2)\n",
    "            lstm_model.fit(x_train=x_train, y_train=y_train)\n",
    "            pred, label = lstm_model.predict(x_test, y_test)\n",
    "            fold_score.append(custom_r2_func(pred, label))\n",
    "        fold_score = np.median(fold_score)\n",
    "        within_score[df1.session[0]] = fold_score\n",
    "\n",
    "        aligned_score[df1.session[0]] = {}\n",
    "        unaligned_score[df1.session[0]] = {}\n",
    "        for j, df2 in enumerate(tqdm(allDFs)):\n",
    "            if j <= i: continue\n",
    "            if df1.monkey[0] == df2.monkey[0]: continue\n",
    "            if 'Chewie' in df1.monkey[0] and 'Chewie' in df2.monkey[0]: continue\n",
    "\n",
    "            AllData, AllVel = defs.get_data_array_and_vel([df1,df2],\n",
    "                                                        defs.exec_epoch_decode, area=defs.areas[2], n_components=defs.n_components)\n",
    "            # adding history\n",
    "            AllData = dt.add_history_to_data_array(AllData,defs.MAX_HISTORY)\n",
    "            AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "            AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "\n",
    "            AllData1 = AllData[0,...]\n",
    "            AllData2 = AllData[1,...]\n",
    "            AllVel1 = AllVel[0,...]\n",
    "            AllVel2 = AllVel[1,...]\n",
    "            # resizing\n",
    "            *_,n_time,n_comp = AllData1.shape\n",
    "\n",
    "            X1 = AllData1.reshape((-1,n_comp))\n",
    "            X2 = AllData2.reshape((-1,n_comp))\n",
    "            AllVel2 = AllVel2.reshape((-1,n_time,2))\n",
    "            AllVel1 = AllVel1.reshape((-1,n_time,2))\n",
    "\n",
    "            # train the aligned\n",
    "            *_,U,V = dt.canoncorr(X1, X2, fullReturn=True)\n",
    "            U = U.reshape((-1,n_time,n_comp))\n",
    "            V = V.reshape((-1,n_time,n_comp))\n",
    "            X1 = X1.reshape((-1,n_time,n_comp))\n",
    "            X2 = X2.reshape((-1,n_time,n_comp))\n",
    "\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=2)\n",
    "            lstm_model.fit(x_train=U, y_train=AllVel1)\n",
    "            pred, label = lstm_model.predict(V, AllVel2)\n",
    "            aligned_score[df1.session[0]][df2.session[0]]=custom_r2_func(pred, label).mean()\n",
    "            #================================\n",
    "            # Unaligned\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=2)\n",
    "            lstm_model.fit(x_train=X1, y_train=AllVel1)\n",
    "            pred, label = lstm_model.predict(X2, AllVel2)\n",
    "            unaligned_score[df1.session[0]][df2.session[0]]=custom_r2_func(pred, label).mean()\n",
    "\n",
    "    #======================== PLOTTING\n",
    "    pop_within = np.array(list(within_score.values()))\n",
    "    pop_aligned = np.array([val for key in aligned_score for val in aligned_score[key].values()])\n",
    "    pop_unaligned = np.array([val for key in unaligned_score for val in unaligned_score[key].values()])\n",
    "\n",
    "    ax.errorbar(1, pop_aligned.mean(), np.std(pop_aligned), label='Across\\n' r'(\\textit{aligned})',\n",
    "                color=params.colors.MainCC, fmt='-o', capsize=1.5)    \n",
    "    ax.errorbar(0, pop_unaligned.mean(), np.std(pop_unaligned), label='Across\\n' r'(\\textit{unaligned})',\n",
    "                color=params.colors.LowerCC, fmt='-o', capsize=1.5)\n",
    "    ax.errorbar(2, pop_within.mean(), np.std(pop_within), label='Within',\n",
    "                color=params.colors.UpperCC, fmt='-o', capsize=1.5)\n",
    "\n",
    "    for file1, nested_dict in aligned_score.items():\n",
    "        wi_val1 = within_score[file1]\n",
    "        for file2, al_val in nested_dict.items():\n",
    "            wi_val2 = within_score[file2]\n",
    "            unal_val = unaligned_score[file1][file2]\n",
    "            ax.plot([0,1,2], [unal_val, al_val, wi_val1],\n",
    "                    color='gray', lw=.2, zorder=6, marker = 'o', ms=.1, alpha=.2)\n",
    "            ax.plot([1,2], [al_val, wi_val2],\n",
    "                    color='gray', lw=.2, zorder=6, marker = 'o', ms=.1, alpha=.2)\n",
    "\n",
    "    \n",
    "    ax.set_xlim([-0.2,2.2])\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(['Across\\n' r'(\\textit{unaligned})',\n",
    "                        'Across\\n' r'(\\textit{aligned})',\n",
    "                        'Within'])\n",
    "    ax.set_ylabel('Prediction accuracy ($R^2$)')\n",
    "    # ax.set_ylim([-1,1])\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "    # ax.spines['top'].set_visible(False)\n",
    "    # ax.spines['right'].set_visible(False)\n",
    "    # ax.spines['bottom'].set_bounds([0,2])\n",
    "    # ax.spines['left'].set_bounds([0,1])\n",
    "\n",
    "    return unaligned_score, aligned_score, within_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5376e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)  \n",
    "    pop_unaligned, pop_aligned, pop_within = plot_monkey_decoding(ax, allDFs, custom_r2_vaf)\n",
    "\n",
    "    fig.savefig(params.figPath / 'decoding-vaf.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    np.savez('vaf-values.npz', pop_unaligned=pop_unaligned,\n",
    "                pop_aligned=pop_aligned,\n",
    "                pop_within=pop_within)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444540ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('vaf-values.npz', mmap_mode=None)\n",
    "pop_unaligned = data['pop_unaligned']\n",
    "pop_aligned = data['pop_aligned']\n",
    "pop_within = data['pop_within']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "577ada39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.86936879e-01,  3.63589287e-01, -1.25865841e+00,  4.25210595e-01,\n",
       "       -2.29348779e-01, -1.41778708e-01, -8.82936192e+00, -1.06046791e+01,\n",
       "       -7.32240200e+00,  2.48987734e-01,  1.58150256e-01, -1.91934705e+00,\n",
       "        4.11232233e-01,  1.73135877e-01, -1.51185989e-02, -1.30105505e+01,\n",
       "       -9.77686691e+00, -7.07736874e+00,  2.24665880e-01,  9.05672908e-02,\n",
       "       -2.02338076e+00,  4.65938330e-01, -1.22789383e-01, -6.74382448e-02,\n",
       "       -9.12819576e+00, -1.02191925e+01, -1.05551071e+01,  4.75576460e-01,\n",
       "        2.37610757e-01, -1.53711057e+00,  5.04640579e-01,  2.06477404e-01,\n",
       "       -5.38489819e-02, -1.20256100e+01, -1.26495800e+01, -7.64232922e+00,\n",
       "        8.73051465e-01,  8.50189626e-01,  2.64721990e-01,  8.03248286e-01,\n",
       "        8.52091432e-01,  8.79665792e-01, -6.68042421e-01, -1.67333126e-01,\n",
       "       -1.71887755e-01,  8.10095310e-01,  8.09421182e-01,  8.77616465e-01,\n",
       "        8.24710369e-01,  8.31699371e-01,  8.70522559e-01, -3.48401546e-01,\n",
       "       -8.65907669e-02,  2.20125496e-01,  8.79136086e-01,  8.72792125e-01,\n",
       "        6.13287568e-01,  7.97870934e-01,  8.49959671e-01,  8.15362215e-01,\n",
       "       -1.24269819e+00, -1.50433040e+00, -5.09255171e-01,  8.59513342e-01,\n",
       "        8.63352358e-01,  4.51411068e-01,  8.25977921e-01,  8.68086874e-01,\n",
       "        8.38125825e-01, -2.49695992e+00, -2.33660483e+00, -1.19204259e+00,\n",
       "        7.97976136e-01,  8.37148368e-01,  7.75068760e-01,  7.54106462e-01,\n",
       "        7.95357764e-01,  8.22919190e-01,  2.03597307e-01,  7.68704414e-02,\n",
       "        2.14167655e-01,  8.26545596e-01,  7.02765822e-01,  8.06478620e-01,\n",
       "        7.36504853e-01,  8.09435666e-01,  8.53451490e-01, -1.05438113e-01,\n",
       "       -6.35477901e-01,  2.98699737e-01,  6.57295763e-01,  7.87750065e-01,\n",
       "        7.12988615e-01,  6.59506023e-01,  7.63109624e-01,  7.70246446e-01,\n",
       "       -6.12267256e-02, -6.73475266e-02,  3.03298235e-03,  8.03411663e-01,\n",
       "        7.97279477e-01,  7.98509657e-01,  7.42626905e-01,  7.88833797e-01,\n",
       "        8.24766934e-01, -4.27075624e-02, -2.90871024e-01,  2.82737672e-01,\n",
       "       -3.26896811e+00, -3.03523588e+00, -1.33867073e+00, -1.90361547e+00,\n",
       "       -2.33687282e+00, -5.88488817e-01,  2.45606363e-01,  1.73672438e-02,\n",
       "        2.14264691e-01, -2.52988815e+00, -2.57187772e+00, -1.95621252e+00,\n",
       "       -1.82089829e+00, -2.01203156e+00, -1.68789363e+00, -1.00887275e+00,\n",
       "       -1.17005992e+00, -7.25833416e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_aligned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cca')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "146bff742f048d001dec7fafb91c8daeb769f9aeaad9c8d129a83c9f9fb9a9b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
