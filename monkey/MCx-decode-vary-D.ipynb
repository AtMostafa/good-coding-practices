{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06debf48",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f206a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os, sys, pathlib\n",
    "from pprint import pprint\n",
    "import gc\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging, warnings\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyaldata as pyal\n",
    "\n",
    "try:\n",
    "    nbPath = pathlib.Path.cwd()\n",
    "    RepoPath = nbPath.parent\n",
    "    os.chdir(RepoPath)\n",
    "\n",
    "    from tools import utilityTools as utility\n",
    "    from tools import dataTools as dt\n",
    "    from tools import lstm\n",
    "    import params\n",
    "    defs = params.monkey_defs\n",
    "    monkey_defs = defs\n",
    "    \n",
    "    set_rc =  params.set_rc_params\n",
    "    set_rc()\n",
    "    root = params.root\n",
    "    reload(params)\n",
    "    reload(defs)\n",
    "\n",
    "finally:\n",
    "    os.chdir(nbPath)\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "\n",
    "    %run \"_dataset-selection.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd20b87-b313-4b4f-96bf-46dfab428c62",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6d2291-28f0-49fc-b850-5f49eff54d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_example_df():\n",
    "    raster_example = defs.raster_example\n",
    "    raster_example_df = []\n",
    "    for session in raster_example:\n",
    "        path = root/session.split('_')[0]/session\n",
    "        df = defs.prep_general(dt.load_pyal_data(path))\n",
    "        # df = pyal.restrict_to_interval(df, epoch_fun=monkey_defs.exec_epoch)\n",
    "        raster_example_df.append(df)\n",
    "    return raster_example_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6aca7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the DFs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "allDFs = prep_example_df()\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bfa03c-23c2-4248-8648-61253a962857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chewie\n",
      "Mihili\n"
     ]
    }
   ],
   "source": [
    "for df in allDFs:\n",
    "    print(df.monkey[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a33ca96e",
   "metadata": {},
   "source": [
    "## Decoding performance with different dimensionalities\n",
    "\n",
    "---\n",
    "For the example sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22544fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monkey_decoding_fix_D(allDFs, custom_r2_func, n_dim = 10):\n",
    "    \n",
    "    defs = monkey_defs\n",
    "\n",
    "\n",
    "    within_score = {}\n",
    "    aligned_score = {}\n",
    "    unaligned_score = {}\n",
    "    for i, df1 in enumerate(tqdm(allDFs)):\n",
    "        AllData, AllVel = defs.get_data_array_and_vel([df1], defs.exec_epoch_decode,\n",
    "                                                    area=defs.areas[2], n_components=n_dim)\n",
    "        # adding history\n",
    "        AllData = dt.add_history_to_data_array(AllData,defs.MAX_HISTORY)\n",
    "        AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "        AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "        AllData1 = AllData[0,...]\n",
    "        AllVel1 = AllVel[0,...]\n",
    "        *_,n_time,n_comp = AllData1.shape\n",
    "        # resizing\n",
    "        X1 = AllData1.reshape((-1,n_time,n_comp))\n",
    "        AllVel1 = AllVel1.reshape((-1,n_time,2))\n",
    "        \n",
    "        fold_score =[]\n",
    "        kf = KFold(n_splits=10)\n",
    "        for train_index, test_index in kf.split(X1[:,0,0]):\n",
    "            x_train, x_test = X1[train_index,...], X1[test_index,...]\n",
    "            y_train, y_test = AllVel1[train_index,...], AllVel1[test_index,...]\n",
    "\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=X1.shape[-1], output_dims=2)\n",
    "            lstm_model.fit(x_train=x_train, y_train=y_train)\n",
    "            pred, label = lstm_model.predict(x_test, y_test)\n",
    "            fold_score.append(custom_r2_func(pred, label))\n",
    "        fold_score = np.median(fold_score)\n",
    "        within_score[df1.session[0]] = fold_score\n",
    "\n",
    "        aligned_score[df1.session[0]] = {}\n",
    "        unaligned_score[df1.session[0]] = {}\n",
    "        for j, df2 in enumerate(tqdm(allDFs)):\n",
    "            if j <= i: continue\n",
    "            if df1.monkey[0] == df2.monkey[0]: continue\n",
    "            if 'Chewie' in df1.monkey[0] and 'Chewie' in df2.monkey[0]: continue\n",
    "\n",
    "            AllData, AllVel = defs.get_data_array_and_vel([df1,df2],\n",
    "                                                        defs.exec_epoch_decode, area=defs.areas[2], n_components=n_dim)\n",
    "            # adding history\n",
    "            AllData = dt.add_history_to_data_array(AllData,defs.MAX_HISTORY)\n",
    "            AllData = AllData[...,defs.MAX_HISTORY:,:]\n",
    "            AllVel = AllVel[...,defs.MAX_HISTORY:,:]\n",
    "\n",
    "            AllData1 = AllData[0,...]\n",
    "            AllData2 = AllData[1,...]\n",
    "            AllVel1 = AllVel[0,...]\n",
    "            AllVel2 = AllVel[1,...]\n",
    "            # resizing\n",
    "            *_,n_time,n_comp = AllData1.shape\n",
    "\n",
    "            X1 = AllData1.reshape((-1,n_comp))\n",
    "            X2 = AllData2.reshape((-1,n_comp))\n",
    "            AllVel2 = AllVel2.reshape((-1,n_time,2))\n",
    "            AllVel1 = AllVel1.reshape((-1,n_time,2))\n",
    "\n",
    "            # train the aligned\n",
    "            *_,U,V = dt.canoncorr(X1, X2, fullReturn=True)\n",
    "            U = U.reshape((-1,n_time,n_comp))\n",
    "            V = V.reshape((-1,n_time,n_comp))\n",
    "            X1 = X1.reshape((-1,n_time,n_comp))\n",
    "            X2 = X2.reshape((-1,n_time,n_comp))\n",
    "\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=2)\n",
    "            lstm_model.fit(x_train=U, y_train=AllVel1)\n",
    "            pred, label = lstm_model.predict(V, AllVel2)\n",
    "            aligned_score[df1.session[0]][df2.session[0]]=custom_r2_func(pred, label).mean()\n",
    "            #================================\n",
    "            # Unaligned\n",
    "            lstm_model = lstm.LSTMDecoder(input_dims=U.shape[-1], output_dims=2)\n",
    "            lstm_model.fit(x_train=X1, y_train=AllVel1)\n",
    "            pred, label = lstm_model.predict(X2, AllVel2)\n",
    "            unaligned_score[df1.session[0]][df2.session[0]]=custom_r2_func(pred, label).mean()\n",
    "\n",
    "    return within_score, aligned_score, unaligned_score\n",
    "\n",
    "def run_decode_var_D(allDFs, custom_r2_func, dim_range=None, redo=False):\n",
    "    if dim_range is None:\n",
    "        dim_range = range(1, defs.n_components + 5)\n",
    "\n",
    "    pop_within = []\n",
    "    pop_aligned = []\n",
    "    pop_unaligned = []\n",
    "    for dim in dim_range:\n",
    "        pathPickle = root / 'monkey-pickles' / f'D{dim}_decode_{custom_r2_func.__name__}.p'\n",
    "        if os.path.exists(pathPickle) and not redo:\n",
    "            with open(pathPickle,\"rb\") as f:\n",
    "                within_score, aligned_score, unaligned_score = pickle.load(f)\n",
    "        else:\n",
    "            within_score, aligned_score, unaligned_score = monkey_decoding_fix_D(allDFs, custom_r2_func, n_dim = dim)\n",
    "            with open(pathPickle, 'wb') as f:\n",
    "                pickle.dump([within_score, aligned_score, unaligned_score], f)\n",
    "                f.close()\n",
    "\n",
    "        pop_within.append(np.array(list(within_score.values())))\n",
    "        pop_aligned.append(np.array([val for key in aligned_score for val in aligned_score[key].values()]))\n",
    "        pop_unaligned.append(np.array([val for key in unaligned_score for val in unaligned_score[key].values()]))\n",
    "\n",
    "    pop_within = np.array(pop_within)\n",
    "    pop_aligned = np.array(pop_aligned)\n",
    "    pop_unaligned = np.array(pop_unaligned)\n",
    "\n",
    "    return pop_within, pop_aligned, pop_unaligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fdcf135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    dim_range = range(1, defs.n_components + 5)\n",
    "\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "    fig, ax = plt.subplots(1,1)  \n",
    "    \n",
    "    pop_within, pop_aligned, pop_unaligned = run_decode_var_D(allDFs, lstm.custom_r2_func, dim_range=dim_range)\n",
    "    \n",
    "    \n",
    "    utility.shaded_errorbar(ax,list(dim_range), pop_within, label='within')\n",
    "    utility.shaded_errorbar(ax,list(dim_range), pop_aligned, label='aligned')\n",
    "    utility.shaded_errorbar(ax,list(dim_range), pop_unaligned, label='unaligned')\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_ylabel('Prediction accuracy ($R^2$)')\n",
    "    ax.set_xlabel('Dimensions')\n",
    "    ax.set_ylim([-.05,1])\n",
    "    ax.set_xticks(list(range(1, defs.n_components + 5)))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_bounds([0,1])\n",
    "    ax.spines['bottom'].set_bounds([1,14])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e181d7b0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## running it for all the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157032b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = []\n",
    "for animal, sessionList in GoodDataList[defs.areas[2]].items():\n",
    "    if 'Mr' in animal:\n",
    "        continue  # to remove MrT\n",
    "    full_list.append((animal,sessionList))\n",
    "full_list = [(animal,session) for animal,sessions in full_list for session in set(sessions)]\n",
    "\n",
    "# load the DFs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "allDFs = []\n",
    "for animal, session in full_list:\n",
    "    path = root/animal/session\n",
    "    allDFs.append(defs.prep_general(dt.load_pyal_data(path)))\n",
    "warnings.filterwarnings(\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    plt.close('all')\n",
    "    set_rc()\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)  \n",
    "    \n",
    "    pop_within, pop_aligned, pop_unaligned = run_decode_var_D(allDFs, lstm.custom_r2_func)\n",
    "    \n",
    "    utility.shaded_errorbar(ax,list(range(1, defs.n_components + 5)), pop_within, label='within')\n",
    "    utility.shaded_errorbar(ax,list(range(1, defs.n_components + 5)), pop_aligned, label='aligned')\n",
    "    utility.shaded_errorbar(ax,list(range(1, defs.n_components + 5)), pop_unaligned, label='unaligned')\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_ylabel('Prediction accuracy ($R^2$)')\n",
    "    ax.set_xlabel('Dimensions')\n",
    "    ax.set_ylim([-.05,1])\n",
    "    ax.set_xticks(list(range(1, defs.n_components + 5)))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_bounds([0,1])\n",
    "    ax.spines['bottom'].set_bounds([1,14])\n",
    "    \n",
    "    fig.savefig(params.figPath / 'decoding-var-dim.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883e4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cca')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "146bff742f048d001dec7fafb91c8daeb769f9aeaad9c8d129a83c9f9fb9a9b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
