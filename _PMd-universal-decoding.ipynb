{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55d5408",
   "metadata": {},
   "source": [
    "# part0: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d45b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "from pprint import pprint\n",
    "import gc\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import logging, warnings\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import Ridge, LinearRegression, SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from tools import utilityTools as utility\n",
    "from tools import dataTools as dt\n",
    "import pyaldata as pyal\n",
    "import set_rc_params as set_rc\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['png2x']\n",
    "reload(dt)\n",
    "reload(set_rc)\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "    # Global params\n",
    "    set_rc.set_rc_params()\n",
    "    root = pathlib.Path(\"/data\")\n",
    "    classifier_model = GaussianProcessClassifier\n",
    "    classifier_params = {}\n",
    "\n",
    "    BIN_SIZE = .03  # sec\n",
    "    WINDOW_prep = (-.4, .05)  # sec\n",
    "    WINDOW_exec = (-.05, .40)  # sec\n",
    "    n_components = 10  # min between M1 and PMd\n",
    "    areas = ('M1', 'PMd')\n",
    "    MAX_HISTORY = 3  #int: no of bins to be added as history\n",
    "\n",
    "    prep_epoch = pyal.generate_epoch_fun(start_point_name='idx_movement_on',\n",
    "                                         rel_start=int(WINDOW_prep[0]/BIN_SIZE),\n",
    "                                         rel_end=int(WINDOW_prep[1]/BIN_SIZE)\n",
    "                                        )\n",
    "    exec_epoch = pyal.generate_epoch_fun(start_point_name='idx_movement_on', \n",
    "                                         rel_start=int(WINDOW_exec[0]/BIN_SIZE),\n",
    "                                         rel_end=int(WINDOW_exec[1]/BIN_SIZE)\n",
    "                                        )\n",
    "    fixation_epoch = pyal.generate_epoch_fun(start_point_name='idx_target_on', \n",
    "                                             rel_start=int(WINDOW_prep[0]/BIN_SIZE),\n",
    "                                             rel_end=int(WINDOW_prep[1]/BIN_SIZE)\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f971f2",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9201a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    def get_target_id(trial):\n",
    "        return int(np.round((trial.target_direction + np.pi) / (0.25*np.pi))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590ad812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the variable `GoodDataList` contains the session names\n"
     ]
    }
   ],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    def prep_general (df):\n",
    "        \"preprocessing general!\"\n",
    "        time_signals = [signal for signal in pyal.get_time_varying_fields(df) if 'spikes' in signal]\n",
    "        df[\"target_id\"] = df.apply(get_target_id, axis=1)  # add a field `target_id` with int values\n",
    "\n",
    "        for signal in time_signals:\n",
    "            df_ = pyal.remove_low_firing_neurons(df, signal, 1)\n",
    "\n",
    "        df_= pyal.select_trials(df, df.result== 'R')\n",
    "        df_= pyal.select_trials(df_, df_.epoch=='BL')\n",
    "\n",
    "        assert np.all(df_.bin_size == .01), 'bin size is not consistent!'\n",
    "        df_ = pyal.combine_time_bins(df_, int(BIN_SIZE/.01))\n",
    "        for signal in time_signals:\n",
    "            df_ = pyal.sqrt_transform_signal(df_, signal)\n",
    "\n",
    "        df_= pyal.add_firing_rates(df_, 'smooth', std=0.05)\n",
    "\n",
    "\n",
    "        return df_\n",
    "\n",
    "\n",
    "    %run dataset_selection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45209f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    def custom_r2_func(y_true, y_pred):\n",
    "        \"$R^2$ value as squared correlation coefficient, as per Gallego, NN 2020\"\n",
    "        return stats.pearsonr(y_true, y_pred)[0] ** 2\n",
    "\n",
    "    custom_r2_scorer = make_scorer(custom_r2_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb1129",
   "metadata": {},
   "source": [
    "# universal decoding of target using a model trained on a different animal\n",
    "\n",
    "\n",
    "Train one decoder and use it to decode the target in other animals.  \n",
    "The logic follows:  \n",
    "CCA gives us: $X_1A\\cong X_2B$  \n",
    "Then: $X_1 \\cong X_2BA^{-1}$  \n",
    "So, we can train a decoder on $X_1$ and, then align any $X_2$ to $X_1$ to get $A$ and $B$.  \n",
    "The same decoder should work on $X_2BA^{-1}$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c411cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    full_list = []\n",
    "    for area in ('dualArea','PMd'):\n",
    "        for animal, sessionList in GoodDataList[area].items():\n",
    "            if 'Mr' in animal:\n",
    "                continue  # to remove MrT\n",
    "            full_list.append((animal,sessionList))\n",
    "    full_list = [(animal,session) for animal,sessions in full_list for session in set(sessions)]\n",
    "\n",
    "    # load the DFs\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    allDFs = []\n",
    "    for animal, session in full_list:\n",
    "        path = root/animal/session\n",
    "        allDFs.append(prep_general(dt.load_pyal_data(path)))\n",
    "    warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d45e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairIndex_uni = []\n",
    "for i, (animal1,session1) in enumerate(full_list):\n",
    "    pairIndex_uni.append((i,[]))\n",
    "    for j, (animal2,session2) in enumerate(full_list):\n",
    "        if animal1 == animal2: continue\n",
    "        if 'Chewie' in animal1 and 'Chewie' in animal2: continue\n",
    "        pairIndex_uni[-1][1].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd287e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12345)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "reg_scores = []\n",
    "for id1, testList in pairIndex_uni:\n",
    "    AllData = dt.get_data_array([allDFs[id1]]+[allDFs[testid] for testid in testList], prep_epoch, area=areas[1], model=n_components)\n",
    "    # adding history -- there is no need for history\n",
    "    AllData = dt.add_history_to_data_array(AllData, MAX_HISTORY)\n",
    "\n",
    "    AllData1 = AllData[0,...] \n",
    "    _,n_trial,n_time,n_comp = AllData1.shape\n",
    "    # resizing\n",
    "    X1 = AllData1.reshape((-1,n_time*n_comp))\n",
    "    AllTar = np.repeat(np.arange(8),n_trial)\n",
    "\n",
    "    trial_index = np.arange(len(AllTar))\n",
    "    # to guarantee shuffled ids\n",
    "    while ((all_id_sh := rng.permutation(trial_index)) == trial_index).all():\n",
    "        continue\n",
    "    trial_index = all_id_sh\n",
    "    X_train, Y_train = X1[trial_index,:], AllTar[trial_index]\n",
    "\n",
    "    # train the decoder\n",
    "    classifier = classifier_model(**classifier_params)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    for testId,_ in enumerate(testList):\n",
    "        AllData2 = AllData[testId+1,...]  # index-0 is for the training dataset above\n",
    "        # resizing\n",
    "        X1 = AllData1.reshape((-1,n_comp))\n",
    "        X2 = AllData2.reshape((-1,n_comp))\n",
    "        \n",
    "        # align the decoder\n",
    "        A,B,*_ = dt.canoncorr(X1, X2, fullReturn=True)\n",
    "        X2_aligned = X2 @ B @ linalg.inv(A) \n",
    "\n",
    "        X2_aligned = X2_aligned.reshape((-1,n_time*n_comp))\n",
    "        AllTar = np.repeat(np.arange(8),n_trial)\n",
    "        \n",
    "        rng.shuffle(trial_index)\n",
    "        X_test, Y_test = X2_aligned[trial_index,:], AllTar[trial_index]\n",
    "\n",
    "        # test the decoder\n",
    "        _score = classifier.score(X_test,Y_test)\n",
    "        reg_scores.append((id1,testId,_score))\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "pop_score_uni = []\n",
    "for _,_,scores in reg_scores:\n",
    "    pop_score_uni.append(scores)\n",
    "pop_score_uni = np.array(pop_score_uni)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    _,ax = plt.subplots()\n",
    "    ax.plot(pop_score_uni,'-o')\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_xlabel('Session pairs')\n",
    "    ax.set_ylabel('Prediction accuracy score')\n",
    "    ax.set_title('Target classifying --- universal classifier')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72da6499f934495e06c03d484049d4696c0f7b78c6b9c64cf8676e9ec2014a6a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
